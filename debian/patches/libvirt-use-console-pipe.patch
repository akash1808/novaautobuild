diff -Naurp nova.orig/Authors nova/Authors
--- nova.orig/Authors	2012-02-27 09:01:19.301005811 -0500
+++ nova/Authors	2012-02-27 09:03:45.361009299 -0500
@@ -146,6 +146,7 @@ Ricardo Carrillo Cruz <emaildericky@gmai
 Rick Clark <rick@openstack.org>
 Rick Harris <rconradharris@gmail.com>
 Rob Kost <kost@isi.edu>
+Robie Basak <robie.basak@canonical.com>
 Russell Bryant <rbryant@redhat.com>
 Russell Sim <russell.sim@gmail.com>
 Ryan Lane <rlane@wikimedia.org>
diff -Naurp nova.orig/Authors.orig nova/Authors.orig
--- nova.orig/Authors.orig	1969-12-31 19:00:00.000000000 -0500
+++ nova/Authors.orig	2012-02-27 09:01:19.301005811 -0500
@@ -0,0 +1,187 @@
+Aaron Lee <aaron.lee@rackspace.com>
+Adam Gandelman <adamg@canonical.com>
+Adam Johnson <adjohn@gmail.com>
+Adrian Smith <adrian_f_smith@dell.com>
+Ahmad Hassan <ahmad.hassan@hp.com>
+Alex Meade <alex.meade@rackspace.com>
+Alexander Sakhnov <asakhnov@mirantis.com>
+Alvaro Lopez Garcia <aloga@ifca.unican.es>
+Andrew Bogott <abogott@wikimedia.org>
+Andrew Clay Shafer <acs@parvuscaptus.com>
+Andrey Brindeyev <abrindeyev@griddynamics.com>
+Andy Smith <code@term.ie>
+Andy Southgate <andy.southgate@citrix.com>
+Anne Gentle <anne@openstack.org>
+Anthony Young <sleepsonthefloor@gmail.com>
+Antony Messerli <ant@openstack.org>
+Armando Migliaccio <Armando.Migliaccio@eu.citrix.com>
+Arvind Somya <asomya@cisco.com>
+Asbjørn Sannes <asbjorn.sannes@interhost.no>
+Ben McGraw <ben@pistoncloud.com>
+Bilal Akhtar <bilalakhtar@ubuntu.com>
+Brad Hall <brad@nicira.com>
+Brad McConnell <bmcconne@rackspace.com>
+Brendan Maguire <B_Maguire@Dell.com>
+Brian Lamar <brian.lamar@rackspace.com>
+Brian Schott <bschott@isi.edu>
+Brian Waldon <brian.waldon@rackspace.com>
+Chiradeep Vittal <chiradeep@cloud.com>
+Chmouel Boudjnah <chmouel@chmouel.com>
+Chris Behrens <cbehrens@codestud.com>
+Christian Berendt <berendt@b1-systems.de>
+Chris Fattarsi <chris.fattarsi@pistoncloud.com>
+Christopher MacGown <chris@pistoncloud.com>
+Chuck Short <zulcss@ubuntu.com>
+Cole Robinson <crobinso@redhat.com>
+Cor Cornelisse <cor@hyves.nl>
+Cory Wright <corywright@gmail.com>
+Dan Prince <dprince@redhat.com>
+Dan Wendlandt <dan@nicira.com>
+Daniel P. Berrange <berrange@redhat.com>
+Dave Lapsley <dlapsley@nicira.com>
+Dave Walker <DaveWalker@ubuntu.com>
+David Pravec <David.Pravec@danix.org>
+David Subiros <david.perez5@hp.com>
+Dean Troyer <dtroyer@gmail.com>
+Deepak Garg <deepak.garg@citrix.com>
+Derek Higgins <derekh@redhat.com>
+Devdeep Singh <devdeep.singh@citrix.com>
+Devendra Modium <dmodium@isi.edu>
+Devin Carlen <devin.carlen@gmail.com>
+Donal Lafferty <donal.lafferty@citrix.com>
+Dong-In David Kang <dkang@isi.edu>
+Duncan McGreggor <duncan@dreamhost.com>
+Ed Leafe <ed@leafe.com>
+Edouard Thuleau <edouard1.thuleau@orange.com>
+Eldar Nugaev <reldan@oscloud.ru>
+Eoghan Glynn <eglynn@redhat.com>
+Eric Day <eday@oddments.org>
+Eric Windisch <eric@cloudscaling.com>
+Evan Callicoat <diopter@gmail.com>
+Ewan Mellor <ewan.mellor@citrix.com>
+François Charlier <francois.charlier@enovance.com>
+Gabe Westmaas <gabe.westmaas@rackspace.com>
+Gary Kotton <garyk@radware.com>
+Gaurav Gupta <gaurav@denali-systems.com>
+Hengqing Hu <hudayou@hotmail.com>
+Hisaharu Ishii <ishii.hisaharu@lab.ntt.co.jp>
+Hisaki Ohara <hisaki.ohara@intel.com>
+Ilya Alekseyev <ilyaalekseyev@acm.org>
+Isaku Yamahata <yamahata@valinux.co.jp>
+Ivan Kolodyazhny <e0ne@e0ne.info>
+Jake Dahn <jake@ansolabs.com>
+James E. Blair <jeblair@hp.com>
+Jason Cannavale <jason.cannavale@rackspace.com>
+Jason Koelker <jason@koelker.net>
+Jay Pipes <jaypipes@gmail.com>
+Jesse Andrews <anotherjesse@gmail.com>
+Jimmy Bergman <jimmy@sigint.se>
+Joe Gordon <jogo@cloudscaling.com>
+Joe Heck <heckj@mac.com>
+Joel Moore <joelbm24@gmail.com>
+Johannes Erdfelt <johannes.erdfelt@rackspace.com>
+John Dewey <john@dewey.ws>
+John Garbutt <john.garbutt@citrix.com>
+John Griffith <john.griffith@solidfire.com>
+John Tran <jtran@attinteractive.com>
+Jonathan Bryce <jbryce@jbryce.com>
+Jordan Rinke <jordan@openstack.org>
+Joseph Suh <jsuh@isi.edu>
+Joseph W. Breu <breu@breu.org>
+Josh Durgin <joshd@hq.newdream.net>
+Josh Kearney <josh@jk0.org>
+Josh Kleinpeter <josh@kleinpeter.org>
+Joshua McKenty <jmckenty@gmail.com>
+Juan G. Hernando Rivero <ghe@debian.org>
+Julien Danjou <julien.danjou@enovance.com>
+Justin Santa Barbara <justin@fathomdb.com>
+Justin Shepherd <jshepher@rackspace.com>
+Kei Masumoto <masumotok@nttdata.co.jp>
+Keisuke Tagami <tagami.keisuke@lab.ntt.co.jp>
+masumoto<masumotok@nttdata.co.jp>
+masukotm<masukotm@nttdata.co.jp>
+Ken Pepple <ken.pepple@gmail.com>
+Kevin Bringard <kbringard@attinteractive.com>
+Kevin L. Mitchell <kevin.mitchell@rackspace.com>
+Kiall Mac Innes <kiall@managedit.ie>
+Kirill Shileev <kshileev@gmail.com>
+Koji Iida <iida.koji@lab.ntt.co.jp>
+Liam Kelleher  <liam.kelleher@hp.com>
+Likitha Shetty <likitha.shetty@citrix.com>
+Loganathan Parthipan <parthipan@hp.com>
+Lorin Hochstein <lorin@isi.edu>
+Lvov Maxim <usrleon@gmail.com>
+Mandell Degerness <mdegerne@gmail.com>
+Mark McLoughlin <markmc@redhat.com>
+Mark Washenberger <mark.washenberger@rackspace.com>
+Maru Newby <mnewby@internap.com>
+Masanori Itoh <itoumsn@nttdata.co.jp>
+Matt Dietz <matt.dietz@rackspace.com>
+Matthew Hooker <matt@cloudscaling.com>
+Michael Basnight <mbasnigh@rackspace.com>
+Michael Gundlach <michael.gundlach@rackspace.com>
+Michael Still <mikal@stillhq.com>
+Mike Lundy <mike@pistoncloud.com>
+Mike Pittaro <mikeyp@lahondaresearch.org>
+Mike Scherbakov <mihgen@gmail.com>
+Mikyung Kang <mkkang@isi.edu>
+Mohammed Naser <mnaser@vexxhost.com>
+Monsyne Dragon <mdragon@rackspace.com>
+Monty Taylor <mordred@inaugust.com>
+MORITA Kazutaka <morita.kazutaka@gmail.com>
+MotoKen <motokentsai@gmail.com>
+Muneyuki Noguchi <noguchimn@nttdata.co.jp>
+Nachi Ueno <ueno.nachi@lab.ntt.co.jp>
+Naveed Massjouni <naveedm9@gmail.com>
+Nick Bartos <nick@pistoncloud.com>
+Nikhil Komawar <nikhil.komawar@rackspace.com>
+Nikolay Sokolov <nsokolov@griddynamics.com>
+Nirmal Ranganathan <rnirmal@gmail.com>
+Ollie Leahy <oliver.leahy@hp.com>
+Pádraig Brady <pbrady@redhat.com>
+Paul Voccio <paul@openstack.org>
+Philip Knouff <philip.knouff@mailtrust.com>
+Renuka Apte <renuka.apte@citrix.com>
+Ricardo Carrillo Cruz <emaildericky@gmail.com>
+Rick Clark <rick@openstack.org>
+Rick Harris <rconradharris@gmail.com>
+Rob Kost <kost@isi.edu>
+Russell Bryant <rbryant@redhat.com>
+Russell Sim <russell.sim@gmail.com>
+Ryan Lane <rlane@wikimedia.org>
+Ryan Lucio <rlucio@internap.com>
+Ryu Ishimoto <ryu@midokura.jp>
+Salvatore Orlando <salvatore.orlando@eu.citrix.com>
+Sandy Walsh <sandy.walsh@rackspace.com>
+Sateesh Chodapuneedi <sateesh.chodapuneedi@citrix.com>
+Scott Moser <smoser@ubuntu.com>
+Soren Hansen <soren.hansen@rackspace.com>
+Stanislaw Pitucha <stanislaw.pitucha@hp.com>
+Stephanie Reese <reese.sm@gmail.com>
+Thierry Carrez <thierry@openstack.org>
+Tim Simpson <tim.simpson@rackspace.com>
+Todd Willey <todd@ansolabs.com>
+Tomoe Sugihara <tomoe@midokura.com>
+Tomoya Masuko<masukotm@nttdata.co.jp>
+Thorsten Tarrach <thorsten@atomia.com>
+Trey Morris <trey.morris@rackspace.com>
+Troy Toman <troy.toman@rackspace.com>
+Tushar Patil <tushar.vitthal.patil@gmail.com>
+Unmesh Gurjar <unmesh.gurjar@vertex.co.in>
+Vasiliy Shlykov <vash@vasiliyshlykov.org>
+Vishvananda Ishaya <vishvananda@gmail.com>
+Vivek Y S <vivek.ys@gmail.com>
+Vladimir Popovski <vladimir@zadarastorage.com>
+William Henry <whenry@redhat.com>
+William Kelly <william.kelly@rackspace.com>
+William Wolf <throughnothing@gmail.com>
+Yaguang Tang <heut2008@gmail.com>
+Yoshiaki Tamura <yoshi@midokura.jp>
+Youcef Laribi <Youcef.Laribi@eu.citrix.com>
+Yun Mao <yunmao@gmail.com>
+Yun Shen <Yun.Shen@hp.com>
+Yuriy Taraday <yorik.sar@gmail.com>
+Zed Shaw <zedshaw@zedshaw.com>
+Zhixue Wu <Zhixue.Wu@citrix.com>
+Zhongyue Luo <lzyeval@gmail.com>
+Ziad Sawalha <github@highbridgellc.com>
diff -Naurp nova.orig/nova/tests/test_libvirt.py nova/nova/tests/test_libvirt.py
--- nova.orig/nova/tests/test_libvirt.py	2012-02-27 09:01:19.393005813 -0500
+++ nova/nova/tests/test_libvirt.py	2012-02-27 09:03:45.365009298 -0500
@@ -872,7 +872,7 @@ class LibvirtConnTestCase(test.TestCase)
             (lambda t: _ipv4_like(t.findall(parameter)[1].get('value'),
                                   '192.168.*.1'), True),
             (lambda t: t.find('./devices/serial/source').get(
-                'path').split('/')[1], 'console.log'),
+                'path').split('/')[1], 'console.fifo'),
             (lambda t: t.find('./memory').text, '2097152')]
         if rescue:
             common_checks += [
@@ -2312,3 +2312,53 @@ class LibvirtConnectionTestCase(test.Tes
 
         ref = self.libvirtconnection.finish_revert_migration(ins_ref, None)
         self.assertTrue(isinstance(ref, eventlet.event.Event))
+
+class ConsoleLoggerTestCase(test.TestCase):
+    def setUp(self):
+        super(ConsoleLoggerTestCase, self).setUp()
+        eventlet.monkey_patch()
+        self.directory_path = tempfile.mkdtemp()
+        self.ringbuffer_path = os.path.join(self.directory_path, 'ring')
+        self.fifo_path = os.path.join(self.directory_path, 'fifo')
+        os.mkfifo(self.fifo_path)
+        self.console_logger = connection.ConsoleLogger(self.fifo_path,
+                                                       self.ringbuffer_path)
+        eventlet.sleep(0)
+
+    def testWriteBytes(self, reopen_writer=False, reopen_reader=False):
+        fd = os.open(self.fifo_path, os.O_WRONLY)
+        os.write(fd, '0')
+        eventlet.sleep(0)
+        eventlet.sleep(0)
+        self.assertEquals(self.console_logger.ringbuffer.peek(), '0')
+        if reopen_writer:
+            os.close(fd)
+            fd = os.open(self.fifo_path, os.O_WRONLY)
+        if reopen_reader:
+            self.console_logger.close()
+            self.console_logger = connection.ConsoleLogger(
+                    self.fifo_path,
+                    self.ringbuffer_path)
+            eventlet.sleep(0)
+        os.write(fd, '1')
+        eventlet.sleep(0)
+        eventlet.sleep(0)
+        self.assertEquals(self.console_logger.ringbuffer.peek(), '01')
+        os.close(fd)
+
+    def testReopenWriter(self):
+        self.testWriteBytes(reopen_writer=True)
+
+    def testReopenReader(self):
+        self.testWriteBytes(reopen_reader=True)
+
+    def testReopenBoth(self):
+        self.testWriteBytes(reopen_writer=True, reopen_reader=True)
+
+    def tearDown(self):
+        super(ConsoleLoggerTestCase, self).tearDown()
+        if self.console_logger:
+            self.console_logger.close()
+        os.unlink(self.ringbuffer_path)
+        os.unlink(self.fifo_path)
+        os.rmdir(self.directory_path)
diff -Naurp nova.orig/nova/tests/test_utils.py.orig nova/nova/tests/test_utils.py.orig
--- nova.orig/nova/tests/test_utils.py.orig	1969-12-31 19:00:00.000000000 -0500
+++ nova/nova/tests/test_utils.py.orig	2012-02-27 09:01:19.000000000 -0500
@@ -0,0 +1,962 @@
+# vim: tabstop=4 shiftwidth=4 softtabstop=4
+
+#    Copyright 2011 Justin Santa Barbara
+#
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+
+import __builtin__
+import datetime
+import hashlib
+import os
+import os.path
+import socket
+import StringIO
+import tempfile
+
+import iso8601
+import mox
+
+import nova
+from nova import exception
+from nova import flags
+from nova import test
+from nova import utils
+
+
+FLAGS = flags.FLAGS
+
+
+class ExecuteTestCase(test.TestCase):
+    def test_retry_on_failure(self):
+        fd, tmpfilename = tempfile.mkstemp()
+        _, tmpfilename2 = tempfile.mkstemp()
+        try:
+            fp = os.fdopen(fd, 'w+')
+            fp.write('''#!/bin/sh
+# If stdin fails to get passed during one of the runs, make a note.
+if ! grep -q foo
+then
+    echo 'failure' > "$1"
+fi
+# If stdin has failed to get passed during this or a previous run, exit early.
+if grep failure "$1"
+then
+    exit 1
+fi
+runs="$(cat $1)"
+if [ -z "$runs" ]
+then
+    runs=0
+fi
+runs=$(($runs + 1))
+echo $runs > "$1"
+exit 1
+''')
+            fp.close()
+            os.chmod(tmpfilename, 0755)
+            self.assertRaises(exception.ProcessExecutionError,
+                              utils.execute,
+                              tmpfilename, tmpfilename2, attempts=10,
+                              process_input='foo',
+                              delay_on_retry=False)
+            fp = open(tmpfilename2, 'r+')
+            runs = fp.read()
+            fp.close()
+            self.assertNotEquals(runs.strip(), 'failure', 'stdin did not '
+                                                          'always get passed '
+                                                          'correctly')
+            runs = int(runs.strip())
+            self.assertEquals(runs, 10,
+                              'Ran %d times instead of 10.' % (runs,))
+        finally:
+            os.unlink(tmpfilename)
+            os.unlink(tmpfilename2)
+
+    def test_unknown_kwargs_raises_error(self):
+        self.assertRaises(exception.Error,
+                          utils.execute,
+                          '/usr/bin/env', 'true',
+                          this_is_not_a_valid_kwarg=True)
+
+    def test_check_exit_code_boolean(self):
+        utils.execute('/usr/bin/env', 'false', check_exit_code=False)
+        self.assertRaises(exception.ProcessExecutionError,
+                          utils.execute,
+                          '/usr/bin/env', 'false', check_exit_code=True)
+
+    def test_no_retry_on_success(self):
+        fd, tmpfilename = tempfile.mkstemp()
+        _, tmpfilename2 = tempfile.mkstemp()
+        try:
+            fp = os.fdopen(fd, 'w+')
+            fp.write('''#!/bin/sh
+# If we've already run, bail out.
+grep -q foo "$1" && exit 1
+# Mark that we've run before.
+echo foo > "$1"
+# Check that stdin gets passed correctly.
+grep foo
+''')
+            fp.close()
+            os.chmod(tmpfilename, 0755)
+            utils.execute(tmpfilename,
+                          tmpfilename2,
+                          process_input='foo',
+                          attempts=2)
+        finally:
+            os.unlink(tmpfilename)
+            os.unlink(tmpfilename2)
+
+
+class GetFromPathTestCase(test.TestCase):
+    def test_tolerates_nones(self):
+        f = utils.get_from_path
+
+        input = []
+        self.assertEquals([], f(input, "a"))
+        self.assertEquals([], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [None]
+        self.assertEquals([], f(input, "a"))
+        self.assertEquals([], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': None}]
+        self.assertEquals([], f(input, "a"))
+        self.assertEquals([], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': {'b': None}}]
+        self.assertEquals([{'b': None}], f(input, "a"))
+        self.assertEquals([], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': {'b': {'c': None}}}]
+        self.assertEquals([{'b': {'c': None}}], f(input, "a"))
+        self.assertEquals([{'c': None}], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': {'b': {'c': None}}}, {'a': None}]
+        self.assertEquals([{'b': {'c': None}}], f(input, "a"))
+        self.assertEquals([{'c': None}], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': {'b': {'c': None}}}, {'a': {'b': None}}]
+        self.assertEquals([{'b': {'c': None}}, {'b': None}], f(input, "a"))
+        self.assertEquals([{'c': None}], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+    def test_does_select(self):
+        f = utils.get_from_path
+
+        input = [{'a': 'a_1'}]
+        self.assertEquals(['a_1'], f(input, "a"))
+        self.assertEquals([], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': {'b': 'b_1'}}]
+        self.assertEquals([{'b': 'b_1'}], f(input, "a"))
+        self.assertEquals(['b_1'], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': {'b': {'c': 'c_1'}}}]
+        self.assertEquals([{'b': {'c': 'c_1'}}], f(input, "a"))
+        self.assertEquals([{'c': 'c_1'}], f(input, "a/b"))
+        self.assertEquals(['c_1'], f(input, "a/b/c"))
+
+        input = [{'a': {'b': {'c': 'c_1'}}}, {'a': None}]
+        self.assertEquals([{'b': {'c': 'c_1'}}], f(input, "a"))
+        self.assertEquals([{'c': 'c_1'}], f(input, "a/b"))
+        self.assertEquals(['c_1'], f(input, "a/b/c"))
+
+        input = [{'a': {'b': {'c': 'c_1'}}},
+                 {'a': {'b': None}}]
+        self.assertEquals([{'b': {'c': 'c_1'}}, {'b': None}], f(input, "a"))
+        self.assertEquals([{'c': 'c_1'}], f(input, "a/b"))
+        self.assertEquals(['c_1'], f(input, "a/b/c"))
+
+        input = [{'a': {'b': {'c': 'c_1'}}},
+                 {'a': {'b': {'c': 'c_2'}}}]
+        self.assertEquals([{'b': {'c': 'c_1'}}, {'b': {'c': 'c_2'}}],
+                          f(input, "a"))
+        self.assertEquals([{'c': 'c_1'}, {'c': 'c_2'}], f(input, "a/b"))
+        self.assertEquals(['c_1', 'c_2'], f(input, "a/b/c"))
+
+        self.assertEquals([], f(input, "a/b/c/d"))
+        self.assertEquals([], f(input, "c/a/b/d"))
+        self.assertEquals([], f(input, "i/r/t"))
+
+    def test_flattens_lists(self):
+        f = utils.get_from_path
+
+        input = [{'a': [1, 2, 3]}]
+        self.assertEquals([1, 2, 3], f(input, "a"))
+        self.assertEquals([], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': {'b': [1, 2, 3]}}]
+        self.assertEquals([{'b': [1, 2, 3]}], f(input, "a"))
+        self.assertEquals([1, 2, 3], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': {'b': [1, 2, 3]}}, {'a': {'b': [4, 5, 6]}}]
+        self.assertEquals([1, 2, 3, 4, 5, 6], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': [{'b': [1, 2, 3]}, {'b': [4, 5, 6]}]}]
+        self.assertEquals([1, 2, 3, 4, 5, 6], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = [{'a': [1, 2, {'b': 'b_1'}]}]
+        self.assertEquals([1, 2, {'b': 'b_1'}], f(input, "a"))
+        self.assertEquals(['b_1'], f(input, "a/b"))
+
+    def test_bad_xpath(self):
+        f = utils.get_from_path
+
+        self.assertRaises(exception.Error, f, [], None)
+        self.assertRaises(exception.Error, f, [], "")
+        self.assertRaises(exception.Error, f, [], "/")
+        self.assertRaises(exception.Error, f, [], "/a")
+        self.assertRaises(exception.Error, f, [], "/a/")
+        self.assertRaises(exception.Error, f, [], "//")
+        self.assertRaises(exception.Error, f, [], "//a")
+        self.assertRaises(exception.Error, f, [], "a//a")
+        self.assertRaises(exception.Error, f, [], "a//a/")
+        self.assertRaises(exception.Error, f, [], "a/a/")
+
+    def test_real_failure1(self):
+        # Real world failure case...
+        #  We weren't coping when the input was a Dictionary instead of a List
+        # This led to test_accepts_dictionaries
+        f = utils.get_from_path
+
+        inst = {'fixed_ip': {'floating_ips': [{'address': '1.2.3.4'}],
+                             'address': '192.168.0.3'},
+                'hostname': ''}
+
+        private_ips = f(inst, 'fixed_ip/address')
+        public_ips = f(inst, 'fixed_ip/floating_ips/address')
+        self.assertEquals(['192.168.0.3'], private_ips)
+        self.assertEquals(['1.2.3.4'], public_ips)
+
+    def test_accepts_dictionaries(self):
+        f = utils.get_from_path
+
+        input = {'a': [1, 2, 3]}
+        self.assertEquals([1, 2, 3], f(input, "a"))
+        self.assertEquals([], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = {'a': {'b': [1, 2, 3]}}
+        self.assertEquals([{'b': [1, 2, 3]}], f(input, "a"))
+        self.assertEquals([1, 2, 3], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = {'a': [{'b': [1, 2, 3]}, {'b': [4, 5, 6]}]}
+        self.assertEquals([1, 2, 3, 4, 5, 6], f(input, "a/b"))
+        self.assertEquals([], f(input, "a/b/c"))
+
+        input = {'a': [1, 2, {'b': 'b_1'}]}
+        self.assertEquals([1, 2, {'b': 'b_1'}], f(input, "a"))
+        self.assertEquals(['b_1'], f(input, "a/b"))
+
+
+class GenericUtilsTestCase(test.TestCase):
+    def test_parse_server_string(self):
+        result = utils.parse_server_string('::1')
+        self.assertEqual(('::1', ''), result)
+        result = utils.parse_server_string('[::1]:8773')
+        self.assertEqual(('::1', '8773'), result)
+        result = utils.parse_server_string('2001:db8::192.168.1.1')
+        self.assertEqual(('2001:db8::192.168.1.1', ''), result)
+        result = utils.parse_server_string('[2001:db8::192.168.1.1]:8773')
+        self.assertEqual(('2001:db8::192.168.1.1', '8773'), result)
+        result = utils.parse_server_string('192.168.1.1')
+        self.assertEqual(('192.168.1.1', ''), result)
+        result = utils.parse_server_string('192.168.1.2:8773')
+        self.assertEqual(('192.168.1.2', '8773'), result)
+        result = utils.parse_server_string('192.168.1.3')
+        self.assertEqual(('192.168.1.3', ''), result)
+        result = utils.parse_server_string('www.example.com:8443')
+        self.assertEqual(('www.example.com', '8443'), result)
+        result = utils.parse_server_string('www.example.com')
+        self.assertEqual(('www.example.com', ''), result)
+        # error case
+        result = utils.parse_server_string('www.exa:mple.com:8443')
+        self.assertEqual(('', ''), result)
+
+    def test_hostname_unicode_sanitization(self):
+        hostname = u"\u7684.test.example.com"
+        self.assertEqual("test.example.com",
+                         utils.sanitize_hostname(hostname))
+
+    def test_hostname_sanitize_periods(self):
+        hostname = "....test.example.com..."
+        self.assertEqual("test.example.com",
+                         utils.sanitize_hostname(hostname))
+
+    def test_hostname_sanitize_dashes(self):
+        hostname = "----test.example.com---"
+        self.assertEqual("test.example.com",
+                         utils.sanitize_hostname(hostname))
+
+    def test_hostname_sanitize_characters(self):
+        hostname = "(#@&$!(@*--#&91)(__=+--test-host.example!!.com-0+"
+        self.assertEqual("91----test-host.example.com-0",
+                         utils.sanitize_hostname(hostname))
+
+    def test_hostname_translate(self):
+        hostname = "<}\x1fh\x10e\x08l\x02l\x05o\x12!{>"
+        self.assertEqual("hello", utils.sanitize_hostname(hostname))
+
+    def test_bool_from_str(self):
+        self.assertTrue(utils.bool_from_str('1'))
+        self.assertTrue(utils.bool_from_str('2'))
+        self.assertTrue(utils.bool_from_str('-1'))
+        self.assertTrue(utils.bool_from_str('true'))
+        self.assertTrue(utils.bool_from_str('True'))
+        self.assertTrue(utils.bool_from_str('tRuE'))
+        self.assertFalse(utils.bool_from_str('False'))
+        self.assertFalse(utils.bool_from_str('false'))
+        self.assertFalse(utils.bool_from_str('0'))
+        self.assertFalse(utils.bool_from_str(None))
+        self.assertFalse(utils.bool_from_str('junk'))
+
+    def test_generate_glance_url(self):
+        generated_url = utils.generate_glance_url()
+        actual_url = "http://%s:%d" % (FLAGS.glance_host, FLAGS.glance_port)
+        self.assertEqual(generated_url, actual_url)
+
+    def test_read_cached_file(self):
+        self.mox.StubOutWithMock(os.path, "getmtime")
+        os.path.getmtime(mox.IgnoreArg()).AndReturn(1)
+        self.mox.ReplayAll()
+
+        cache_data = {"data": 1123, "mtime": 1}
+        data = utils.read_cached_file("/this/is/a/fake", cache_data)
+        self.assertEqual(cache_data["data"], data)
+
+    def test_read_modified_cached_file(self):
+        self.mox.StubOutWithMock(os.path, "getmtime")
+        self.mox.StubOutWithMock(__builtin__, 'open')
+        os.path.getmtime(mox.IgnoreArg()).AndReturn(2)
+
+        fake_contents = "lorem ipsum"
+        fake_file = self.mox.CreateMockAnything()
+        fake_file.read().AndReturn(fake_contents)
+        fake_context_manager = self.mox.CreateMockAnything()
+        fake_context_manager.__enter__().AndReturn(fake_file)
+        fake_context_manager.__exit__(mox.IgnoreArg(),
+                                      mox.IgnoreArg(),
+                                      mox.IgnoreArg())
+
+        __builtin__.open(mox.IgnoreArg()).AndReturn(fake_context_manager)
+
+        self.mox.ReplayAll()
+        cache_data = {"data": 1123, "mtime": 1}
+        self.reload_called = False
+
+        def test_reload(reloaded_data):
+            self.assertEqual(reloaded_data, fake_contents)
+            self.reload_called = True
+
+        data = utils.read_cached_file("/this/is/a/fake", cache_data,
+                                                reload_func=test_reload)
+        self.mox.UnsetStubs()
+        self.assertEqual(data, fake_contents)
+        self.assertTrue(self.reload_called)
+
+    def test_generate_password(self):
+        password = utils.generate_password()
+        self.assertTrue([c for c in password if c in '0123456789'])
+        self.assertTrue([c for c in password
+                         if c in 'abcdefghijklmnopqrstuvwxyz'])
+        self.assertTrue([c for c in password
+                         if c in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'])
+
+    def test_read_file_as_root(self):
+        def fake_execute(*args, **kwargs):
+            if args[1] == 'bad':
+                raise exception.ProcessExecutionError
+            return 'fakecontents', None
+
+        self.stubs.Set(utils, 'execute', fake_execute)
+        contents = utils.read_file_as_root('good')
+        self.assertEqual(contents, 'fakecontents')
+        self.assertRaises(exception.FileNotFound,
+                          utils.read_file_as_root, 'bad')
+
+
+class IsUUIDLikeTestCase(test.TestCase):
+    def assertUUIDLike(self, val, expected):
+        result = utils.is_uuid_like(val)
+        self.assertEqual(result, expected)
+
+    def test_good_uuid(self):
+        val = 'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa'
+        self.assertUUIDLike(val, True)
+
+    def test_integer_passed(self):
+        val = 1
+        self.assertUUIDLike(val, False)
+
+    def test_non_uuid_string_passed(self):
+        val = 'foo-fooo'
+        self.assertUUIDLike(val, False)
+
+    def test_non_uuid_string_passed2(self):
+        val = 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx'
+        self.assertUUIDLike(val, False)
+
+    def test_gen_valid_uuid(self):
+        self.assertUUIDLike(str(utils.gen_uuid()), True)
+
+
+class ToPrimitiveTestCase(test.TestCase):
+    def test_list(self):
+        self.assertEquals(utils.to_primitive([1, 2, 3]), [1, 2, 3])
+
+    def test_empty_list(self):
+        self.assertEquals(utils.to_primitive([]), [])
+
+    def test_tuple(self):
+        self.assertEquals(utils.to_primitive((1, 2, 3)), [1, 2, 3])
+
+    def test_dict(self):
+        self.assertEquals(utils.to_primitive(dict(a=1, b=2, c=3)),
+                          dict(a=1, b=2, c=3))
+
+    def test_empty_dict(self):
+        self.assertEquals(utils.to_primitive({}), {})
+
+    def test_datetime(self):
+        x = datetime.datetime(1, 2, 3, 4, 5, 6, 7)
+        self.assertEquals(utils.to_primitive(x), "0001-02-03 04:05:06.000007")
+
+    def test_iter(self):
+        class IterClass(object):
+            def __init__(self):
+                self.data = [1, 2, 3, 4, 5]
+                self.index = 0
+
+            def __iter__(self):
+                return self
+
+            def next(self):
+                if self.index == len(self.data):
+                    raise StopIteration
+                self.index = self.index + 1
+                return self.data[self.index - 1]
+
+        x = IterClass()
+        self.assertEquals(utils.to_primitive(x), [1, 2, 3, 4, 5])
+
+    def test_iteritems(self):
+        class IterItemsClass(object):
+            def __init__(self):
+                self.data = dict(a=1, b=2, c=3).items()
+                self.index = 0
+
+            def __iter__(self):
+                return self
+
+            def next(self):
+                if self.index == len(self.data):
+                    raise StopIteration
+                self.index = self.index + 1
+                return self.data[self.index - 1]
+
+        x = IterItemsClass()
+        ordered = utils.to_primitive(x)
+        ordered.sort()
+        self.assertEquals(ordered, [['a', 1], ['b', 2], ['c', 3]])
+
+    def test_instance(self):
+        class MysteryClass(object):
+            a = 10
+
+            def __init__(self):
+                self.b = 1
+
+        x = MysteryClass()
+        self.assertEquals(utils.to_primitive(x, convert_instances=True),
+                          dict(b=1))
+
+        self.assertEquals(utils.to_primitive(x), x)
+
+    def test_typeerror(self):
+        x = bytearray  # Class, not instance
+        self.assertEquals(utils.to_primitive(x), u"<type 'bytearray'>")
+
+    def test_nasties(self):
+        def foo():
+            pass
+        x = [datetime, foo, dir]
+        ret = utils.to_primitive(x)
+        self.assertEquals(len(ret), 3)
+        self.assertTrue(ret[0].startswith(u"<module 'datetime' from "))
+        self.assertTrue(ret[1].startswith('<function foo at 0x'))
+        self.assertEquals(ret[2], '<built-in function dir>')
+
+
+class MonkeyPatchTestCase(test.TestCase):
+    """Unit test for utils.monkey_patch()."""
+    def setUp(self):
+        super(MonkeyPatchTestCase, self).setUp()
+        self.example_package = 'nova.tests.monkey_patch_example.'
+        self.flags(
+            monkey_patch=True,
+            monkey_patch_modules=[self.example_package + 'example_a' + ':'
+            + self.example_package + 'example_decorator'])
+
+    def test_monkey_patch(self):
+        utils.monkey_patch()
+        nova.tests.monkey_patch_example.CALLED_FUNCTION = []
+        from nova.tests.monkey_patch_example import example_a, example_b
+
+        self.assertEqual('Example function', example_a.example_function_a())
+        exampleA = example_a.ExampleClassA()
+        exampleA.example_method()
+        ret_a = exampleA.example_method_add(3, 5)
+        self.assertEqual(ret_a, 8)
+
+        self.assertEqual('Example function', example_b.example_function_b())
+        exampleB = example_b.ExampleClassB()
+        exampleB.example_method()
+        ret_b = exampleB.example_method_add(3, 5)
+
+        self.assertEqual(ret_b, 8)
+        package_a = self.example_package + 'example_a.'
+        self.assertTrue(package_a + 'example_function_a'
+            in nova.tests.monkey_patch_example.CALLED_FUNCTION)
+
+        self.assertTrue(package_a + 'ExampleClassA.example_method'
+            in nova.tests.monkey_patch_example.CALLED_FUNCTION)
+        self.assertTrue(package_a + 'ExampleClassA.example_method_add'
+            in nova.tests.monkey_patch_example.CALLED_FUNCTION)
+        package_b = self.example_package + 'example_b.'
+        self.assertFalse(package_b + 'example_function_b'
+            in nova.tests.monkey_patch_example.CALLED_FUNCTION)
+        self.assertFalse(package_b + 'ExampleClassB.example_method'
+            in nova.tests.monkey_patch_example.CALLED_FUNCTION)
+        self.assertFalse(package_b + 'ExampleClassB.example_method_add'
+            in nova.tests.monkey_patch_example.CALLED_FUNCTION)
+
+
+class DeprecationTest(test.TestCase):
+    def setUp(self):
+        super(DeprecationTest, self).setUp()
+
+        def fake_warn_deprecated_class(cls, msg):
+            self.warn = ('class', cls, msg)
+
+        def fake_warn_deprecated_function(func, msg):
+            self.warn = ('function', func, msg)
+
+        self.stubs.Set(utils, 'warn_deprecated_class',
+                       fake_warn_deprecated_class)
+        self.stubs.Set(utils, 'warn_deprecated_function',
+                       fake_warn_deprecated_function)
+        self.warn = None
+
+    def test_deprecated_function_no_message(self):
+        def test_function():
+            pass
+
+        decorated = utils.deprecated()(test_function)
+
+        decorated()
+        self.assertEqual(self.warn, ('function', test_function, ''))
+
+    def test_deprecated_function_with_message(self):
+        def test_function():
+            pass
+
+        decorated = utils.deprecated('string')(test_function)
+
+        decorated()
+        self.assertEqual(self.warn, ('function', test_function, 'string'))
+
+    def test_deprecated_class_no_message(self):
+        @utils.deprecated()
+        class TestClass(object):
+            pass
+
+        TestClass()
+        self.assertEqual(self.warn, ('class', TestClass, ''))
+
+    def test_deprecated_class_with_message(self):
+        @utils.deprecated('string')
+        class TestClass(object):
+            pass
+
+        TestClass()
+        self.assertEqual(self.warn, ('class', TestClass, 'string'))
+
+    def test_deprecated_classmethod_no_message(self):
+        @utils.deprecated()
+        class TestClass(object):
+            @classmethod
+            def class_method(cls):
+                pass
+
+        TestClass.class_method()
+        self.assertEqual(self.warn, ('class', TestClass, ''))
+
+    def test_deprecated_classmethod_with_message(self):
+        @utils.deprecated('string')
+        class TestClass(object):
+            @classmethod
+            def class_method(cls):
+                pass
+
+        TestClass.class_method()
+        self.assertEqual(self.warn, ('class', TestClass, 'string'))
+
+    def test_deprecated_staticmethod_no_message(self):
+        @utils.deprecated()
+        class TestClass(object):
+            @staticmethod
+            def static_method():
+                pass
+
+        TestClass.static_method()
+        self.assertEqual(self.warn, ('class', TestClass, ''))
+
+    def test_deprecated_staticmethod_with_message(self):
+        @utils.deprecated('string')
+        class TestClass(object):
+            @staticmethod
+            def static_method():
+                pass
+
+        TestClass.static_method()
+        self.assertEqual(self.warn, ('class', TestClass, 'string'))
+
+    def test_deprecated_instancemethod(self):
+        @utils.deprecated()
+        class TestClass(object):
+            def instance_method(self):
+                pass
+
+        # Instantiate the class...
+        obj = TestClass()
+        self.assertEqual(self.warn, ('class', TestClass, ''))
+
+        # Reset warn...
+        self.warn = None
+
+        # Call the instance method...
+        obj.instance_method()
+
+        # Make sure that did *not* generate a warning
+        self.assertEqual(self.warn, None)
+
+    def test_service_is_up(self):
+        fts_func = datetime.datetime.fromtimestamp
+        fake_now = 1000
+        down_time = 5
+
+        self.flags(service_down_time=down_time)
+        self.mox.StubOutWithMock(utils, 'utcnow')
+
+        # Up (equal)
+        utils.utcnow().AndReturn(fts_func(fake_now))
+        service = {'updated_at': fts_func(fake_now - down_time),
+                   'created_at': fts_func(fake_now - down_time)}
+        self.mox.ReplayAll()
+        result = utils.service_is_up(service)
+        self.assertTrue(result)
+
+        self.mox.ResetAll()
+        # Up
+        utils.utcnow().AndReturn(fts_func(fake_now))
+        service = {'updated_at': fts_func(fake_now - down_time + 1),
+                   'created_at': fts_func(fake_now - down_time + 1)}
+        self.mox.ReplayAll()
+        result = utils.service_is_up(service)
+        self.assertTrue(result)
+
+        self.mox.ResetAll()
+        # Down
+        utils.utcnow().AndReturn(fts_func(fake_now))
+        service = {'updated_at': fts_func(fake_now - down_time - 1),
+                   'created_at': fts_func(fake_now - down_time - 1)}
+        self.mox.ReplayAll()
+        result = utils.service_is_up(service)
+        self.assertFalse(result)
+
+    def test_xhtml_escape(self):
+        self.assertEqual('&quot;foo&quot;', utils.xhtml_escape('"foo"'))
+        self.assertEqual('&apos;foo&apos;', utils.xhtml_escape("'foo'"))
+
+    def test_hash_file(self):
+        data = 'Mary had a little lamb, its fleece as white as snow'
+        flo = StringIO.StringIO(data)
+        h1 = utils.hash_file(flo)
+        h2 = hashlib.sha1(data).hexdigest()
+        self.assertEquals(h1, h2)
+
+
+class Iso8601TimeTest(test.TestCase):
+
+    def _instaneous(self, timestamp, yr, mon, day, hr, min, sec, micro):
+        self.assertEquals(timestamp.year, yr)
+        self.assertEquals(timestamp.month, mon)
+        self.assertEquals(timestamp.day, day)
+        self.assertEquals(timestamp.hour, hr)
+        self.assertEquals(timestamp.minute, min)
+        self.assertEquals(timestamp.second, sec)
+        self.assertEquals(timestamp.microsecond, micro)
+
+    def _do_test(self, str, yr, mon, day, hr, min, sec, micro, shift):
+        DAY_SECONDS = 24 * 60 * 60
+        timestamp = utils.parse_isotime(str)
+        self._instaneous(timestamp, yr, mon, day, hr, min, sec, micro)
+        offset = timestamp.tzinfo.utcoffset(None)
+        self.assertEqual(offset.seconds + offset.days * DAY_SECONDS, shift)
+
+    def test_zulu(self):
+        str = '2012-02-14T20:53:07Z'
+        self._do_test(str, 2012, 02, 14, 20, 53, 7, 0, 0)
+
+    def test_zulu_micros(self):
+        str = '2012-02-14T20:53:07.123Z'
+        self._do_test(str, 2012, 02, 14, 20, 53, 7, 123000, 0)
+
+    def test_offset_east(self):
+        str = '2012-02-14T20:53:07+04:30'
+        offset = 4.5 * 60 * 60
+        self._do_test(str, 2012, 02, 14, 20, 53, 7, 0, offset)
+
+    def test_offset_east_micros(self):
+        str = '2012-02-14T20:53:07.42+04:30'
+        offset = 4.5 * 60 * 60
+        self._do_test(str, 2012, 02, 14, 20, 53, 7, 420000, offset)
+
+    def test_offset_west(self):
+        str = '2012-02-14T20:53:07-05:30'
+        offset = -5.5 * 60 * 60
+        self._do_test(str, 2012, 02, 14, 20, 53, 7, 0, offset)
+
+    def test_offset_west_micros(self):
+        str = '2012-02-14T20:53:07.654321-05:30'
+        offset = -5.5 * 60 * 60
+        self._do_test(str, 2012, 02, 14, 20, 53, 7, 654321, offset)
+
+    def test_compare(self):
+        zulu = utils.parse_isotime('2012-02-14T20:53:07')
+        east = utils.parse_isotime('2012-02-14T20:53:07-01:00')
+        west = utils.parse_isotime('2012-02-14T20:53:07+01:00')
+        self.assertTrue(east > west)
+        self.assertTrue(east > zulu)
+        self.assertTrue(zulu > west)
+
+    def test_compare_micros(self):
+        zulu = utils.parse_isotime('2012-02-14T20:53:07.6544')
+        east = utils.parse_isotime('2012-02-14T19:53:07.654321-01:00')
+        west = utils.parse_isotime('2012-02-14T21:53:07.655+01:00')
+        self.assertTrue(east < west)
+        self.assertTrue(east < zulu)
+        self.assertTrue(zulu < west)
+
+    def test_zulu_roundtrip(self):
+        str = '2012-02-14T20:53:07Z'
+        zulu = utils.parse_isotime(str)
+        self.assertEquals(zulu.tzinfo, iso8601.iso8601.UTC)
+        self.assertEquals(utils.isotime(zulu), str)
+
+    def test_east_roundtrip(self):
+        str = '2012-02-14T20:53:07-07:00'
+        east = utils.parse_isotime(str)
+        self.assertEquals(east.tzinfo.tzname(None), '-07:00')
+        self.assertEquals(utils.isotime(east), str)
+
+    def test_west_roundtrip(self):
+        str = '2012-02-14T20:53:07+11:30'
+        west = utils.parse_isotime(str)
+        self.assertEquals(west.tzinfo.tzname(None), '+11:30')
+        self.assertEquals(utils.isotime(west), str)
+
+    def test_now_roundtrip(self):
+        str = utils.isotime()
+        now = utils.parse_isotime(str)
+        self.assertEquals(now.tzinfo, iso8601.iso8601.UTC)
+        self.assertEquals(utils.isotime(now), str)
+
+    def test_zulu_normalize(self):
+        str = '2012-02-14T20:53:07Z'
+        zulu = utils.parse_isotime(str)
+        normed = utils.normalize_time(zulu)
+        self._instaneous(normed, 2012, 2, 14, 20, 53, 07, 0)
+
+    def test_east_normalize(self):
+        str = '2012-02-14T20:53:07-07:00'
+        east = utils.parse_isotime(str)
+        normed = utils.normalize_time(east)
+        self._instaneous(normed, 2012, 2, 15, 03, 53, 07, 0)
+
+    def test_west_normalize(self):
+        str = '2012-02-14T20:53:07+21:00'
+        west = utils.parse_isotime(str)
+        normed = utils.normalize_time(west)
+        self._instaneous(normed, 2012, 2, 13, 23, 53, 07, 0)
+
+
+class TestLockCleanup(test.TestCase):
+    """unit tests for utils.cleanup_file_locks()"""
+
+    def setUp(self):
+        super(TestLockCleanup, self).setUp()
+
+        self.pid = os.getpid()
+        self.dead_pid = self._get_dead_pid()
+        self.lock_name = 'nova-testlock'
+        self.lock_file = os.path.join(FLAGS.lock_path,
+                                      self.lock_name + '.lock')
+        self.hostname = socket.gethostname()
+        print self.pid, self.dead_pid
+        try:
+            os.unlink(self.lock_file)
+        except OSError as (errno, strerror):
+            if errno == 2:
+                pass
+
+    def _get_dead_pid(self):
+        """get a pid for a process that does not exist"""
+
+        candidate_pid = self.pid - 1
+        while os.path.exists(os.path.join('/proc', str(candidate_pid))):
+            candidate_pid -= 1
+            if candidate_pid == 1:
+                return 0
+        return candidate_pid
+
+    def _get_sentinel_name(self, hostname, pid, thread='MainThread'):
+        return os.path.join(FLAGS.lock_path,
+                            '%s.%s-%d' % (hostname, thread, pid))
+
+    def _create_sentinel(self, hostname, pid, thread='MainThread'):
+        name = self._get_sentinel_name(hostname, pid, thread)
+        open(name, 'wb').close()
+        return name
+
+    def test_clean_stale_locks(self):
+        """verify locks for dead processes are cleaned up"""
+
+        # create sentinels for two processes, us and a 'dead' one
+        # no actve lock
+        sentinel1 = self._create_sentinel(self.hostname, self.pid)
+        sentinel2 = self._create_sentinel(self.hostname, self.dead_pid)
+
+        utils.cleanup_file_locks()
+
+        self.assertTrue(os.path.exists(sentinel1))
+        self.assertFalse(os.path.exists(self.lock_file))
+        self.assertFalse(os.path.exists(sentinel2))
+
+        os.unlink(sentinel1)
+
+    def test_clean_stale_locks_active(self):
+        """verify locks for dead processes are cleaned with an active lock """
+
+        # create sentinels for two processes, us and a 'dead' one
+        # create an active lock for us
+        sentinel1 = self._create_sentinel(self.hostname, self.pid)
+        sentinel2 = self._create_sentinel(self.hostname, self.dead_pid)
+        os.link(sentinel1, self.lock_file)
+
+        utils.cleanup_file_locks()
+
+        self.assertTrue(os.path.exists(sentinel1))
+        self.assertTrue(os.path.exists(self.lock_file))
+        self.assertFalse(os.path.exists(sentinel2))
+
+        os.unlink(sentinel1)
+        os.unlink(self.lock_file)
+
+    def test_clean_stale_with_threads(self):
+        """verify locks for multiple threads are cleaned up """
+
+        # create sentinels for four threads in our process, and a 'dead'
+        # process.  no lock.
+        sentinel1 = self._create_sentinel(self.hostname, self.pid, 'Default-1')
+        sentinel2 = self._create_sentinel(self.hostname, self.pid, 'Default-2')
+        sentinel3 = self._create_sentinel(self.hostname, self.pid, 'Default-3')
+        sentinel4 = self._create_sentinel(self.hostname, self.pid, 'Default-4')
+        sentinel5 = self._create_sentinel(self.hostname, self.dead_pid,
+                                          'Default-1')
+
+        utils.cleanup_file_locks()
+
+        self.assertTrue(os.path.exists(sentinel1))
+        self.assertTrue(os.path.exists(sentinel2))
+        self.assertTrue(os.path.exists(sentinel3))
+        self.assertTrue(os.path.exists(sentinel4))
+        self.assertFalse(os.path.exists(self.lock_file))
+        self.assertFalse(os.path.exists(sentinel5))
+
+        os.unlink(sentinel1)
+        os.unlink(sentinel2)
+        os.unlink(sentinel3)
+        os.unlink(sentinel4)
+
+    def test_clean_stale_with_threads_active(self):
+        """verify locks for multiple threads are cleaned up """
+
+        # create sentinels for four threads in our process, and a 'dead'
+        # process
+        sentinel1 = self._create_sentinel(self.hostname, self.pid, 'Default-1')
+        sentinel2 = self._create_sentinel(self.hostname, self.pid, 'Default-2')
+        sentinel3 = self._create_sentinel(self.hostname, self.pid, 'Default-3')
+        sentinel4 = self._create_sentinel(self.hostname, self.pid, 'Default-4')
+        sentinel5 = self._create_sentinel(self.hostname, self.dead_pid,
+                                          'Default-1')
+
+        os.link(sentinel1, self.lock_file)
+
+        utils.cleanup_file_locks()
+
+        self.assertTrue(os.path.exists(sentinel1))
+        self.assertTrue(os.path.exists(sentinel2))
+        self.assertTrue(os.path.exists(sentinel3))
+        self.assertTrue(os.path.exists(sentinel4))
+        self.assertTrue(os.path.exists(self.lock_file))
+        self.assertFalse(os.path.exists(sentinel5))
+
+        os.unlink(sentinel1)
+        os.unlink(sentinel2)
+        os.unlink(sentinel3)
+        os.unlink(sentinel4)
+        os.unlink(self.lock_file)
+
+    def test_clean_bogus_lockfiles(self):
+        """verify lockfiles are cleaned """
+
+        lock1 = os.path.join(FLAGS.lock_path, 'nova-testlock1.lock')
+        lock2 = os.path.join(FLAGS.lock_path, 'nova-testlock2.lock')
+        lock3 = os.path.join(FLAGS.lock_path, 'testlock3.lock')
+
+        open(lock1, 'wb').close()
+        open(lock2, 'wb').close()
+        open(lock3, 'wb').close()
+
+        utils.cleanup_file_locks()
+
+        self.assertFalse(os.path.exists(lock1))
+        self.assertFalse(os.path.exists(lock2))
+        self.assertTrue(os.path.exists(lock3))
+
+        os.unlink(lock3)
diff -Naurp nova.orig/nova/tests/test_utils.py.rej nova/nova/tests/test_utils.py.rej
--- nova.orig/nova/tests/test_utils.py.rej	1969-12-31 19:00:00.000000000 -0500
+++ nova/nova/tests/test_utils.py.rej	2012-02-27 09:03:45.365009298 -0500
@@ -0,0 +1,72 @@
+--- nova/tests/test_utils.py	2012-02-22 20:57:08.060044569 -0500
++++ nova/tests/test_utils.py	2012-02-22 20:58:15.364044601 -0500
+@@ -17,12 +17,14 @@
+ import __builtin__
+ import datetime
+ import hashlib
++import itertools
+ import os
+ import StringIO
+ import tempfile
+ 
+ import iso8601
+ import mox
++import nose
+ 
+ import nova
+ from nova import exception
+@@ -811,3 +813,54 @@
+         west = utils.parse_isotime(str)
+         normed = utils.normalize_time(west)
+         self._instaneous(normed, 2012, 2, 13, 23, 53, 07, 0)
++ 
++class RingBufferTestCase(test.TestCase):
++    """Unit test for utils.RingBuffer()."""
++    def setUp(self):
++        super(RingBufferTestCase, self).setUp()
++        self.f = tempfile.NamedTemporaryFile()
++        self.r = utils.RingBuffer(self.f.name, max_size=4)
++
++    def tearDown(self):
++        super(RingBufferTestCase, self).tearDown()
++        self.r.close()
++        self.f.close()
++
++    def testEmpty(self):
++        self.assertEquals(self.r.peek(), '')
++
++    def testReOpen(self):
++        self.r.write('1')
++        self.r.close()
++        self.r = utils.RingBuffer(self.f.name, max_size=4)
++        self.assertEquals(self.r.peek(), '1')
++
++
++def testPermutations():
++    """Test various permutations of writing to a RingBuffer.
++
++    Try all permutations of writing [0,5) bytes three times to a RingBuffer
++    of size 4. This makes use of nose's test generator capability so cannot
++    be a subclass of test.TestCase.
++
++    """
++    def check_buffer(r, expected):
++        nose.tools.eq_(r.peek(), expected)
++
++    SIZE = 4
++    for sequence in itertools.product(range(5), range(5), range(5)):
++        f = tempfile.NamedTemporaryFile()
++        r = utils.RingBuffer(f.name, max_size=SIZE)
++        source = itertools.count()
++        expected = ''
++
++        def next_n(n):
++            return ''.join(str(next(source)) for x in range(n))
++        for entry in sequence:
++            to_insert = next_n(entry)
++            expected += to_insert
++            expected = expected[max(0, len(expected) - SIZE):]
++            r.write(to_insert)
++            yield check_buffer, r, expected
++        r.close()
++        f.close()
diff -Naurp nova.orig/nova/utils.py nova/nova/utils.py
--- nova.orig/nova/utils.py	2012-02-27 09:01:19.397005813 -0500
+++ nova/nova/utils.py	2012-02-27 09:03:45.369009296 -0500
@@ -32,6 +32,7 @@ import random
 import re
 import shlex
 import socket
+import stat
 import struct
 import sys
 import time
@@ -54,6 +55,7 @@ from nova import log as logging
 from nova.openstack.common import cfg
 
 
+BITS_PER_BYTE = 8
 LOG = logging.getLogger(__name__)
 ISO_TIME_FORMAT = "%Y-%m-%dT%H:%M:%S"
 PERFECT_TIME_FORMAT = "%Y-%m-%dT%H:%M:%S.%f"
@@ -1523,3 +1525,132 @@ def read_file_as_root(file_path):
         return out
     except exception.ProcessExecutionError:
         raise exception.FileNotFound(file_path=file_path)
+        
+class RingBuffer(object):
+    """Generic userspace on-disk ringbuffer implementation."""
+    _header_max_int = (2 ** (struct.calcsize('I') * BITS_PER_BYTE)) - 1
+    _header_format = 'II'
+    _header_size = struct.calcsize(_header_format)
+
+    def __init__(self, backing_file, max_size=65536):
+        # We need one extra byte as the buffer is kept with
+        # one byte free to avoid the head==tail full/empty
+        # problem
+        max_size += 1
+
+        if not 0 < max_size <= RingBuffer._header_max_int:
+            raise ValueError(_('RingBuffer size out of range'))
+        had_already_existed = os.path.exists(backing_file)
+        self.f = self._open(backing_file)
+        if had_already_existed:
+            file_size = os.fstat(self.f.fileno()).st_size
+            if file_size:
+                current_size = file_size - self._header_size
+                if not 0 < current_size <= RingBuffer._header_max_int:
+                    self.f.close()
+                    raise ValueError(_('Disk RingBuffer size out of range'))
+                self.max_size = current_size
+
+                # If the file doesn't contain a header, assume it is corrupt
+                # and recreate
+                if file_size < self._header_size:
+                    self._write_header(0, 0)  # initialise to empty
+
+                # If head or tail point beyond the file then bomb out
+                head, tail = self._read_header()
+                if head >= current_size or tail >= current_size:
+                    self.f.close()
+                    raise ValueError(_('RingBuffer %s is corrupt') %
+                                     backing_file)
+            else:
+                # File is zero bytes: treat as new file
+                self.max_size = max_size
+                self._initialise_empty_file()
+        else:
+            self.max_size = max_size
+            self._initialise_empty_file()
+
+    def _initialise_empty_file(self):
+        os.ftruncate(self.f.fileno(), self.max_size + self._header_size)
+        self._write_header(0, 0)  # head == tail means no data
+
+    @staticmethod
+    def _open(filename):
+        """Open a file without truncating it for both reading and writing in
+        binary mode."""
+        # Built-in open() cannot open in read/write mode without truncating.
+        fd = os.open(filename, os.O_RDWR | os.O_CREAT, 0666)
+        return os.fdopen(fd, 'w+')
+
+    def _read_header(self):
+        self.f.seek(0)
+        return struct.unpack(self._header_format,
+                             self.f.read(self._header_size))
+
+    def _write_header(self, head, tail):
+        self.f.seek(0)
+        self.f.write(struct.pack(self._header_format, head, tail))
+
+    def _seek(self, pos):
+        """Seek to pos in data (ignoring header)."""
+        self.f.seek(self._header_size + pos)
+
+    def _read_slice(self, start, end):
+        if start == end:
+            return ''
+
+        self._seek(start)
+        return self.f.read(end - start)
+
+    def _write_slice(self, pos, data):
+        self._seek(pos)
+        self.f.write(data)
+
+    def peek(self):
+        """Read the entire ringbuffer without consuming it."""
+        head, tail = self._read_header()
+        if head < tail:
+            # Wraps around
+            before_wrap = self._read_slice(tail, self.max_size)
+            after_wrap = self._read_slice(0, head)
+            return before_wrap + after_wrap
+        else:
+            # Just from here to head
+            return self._read_slice(tail, head)
+
+    def write(self, data):
+        """Write some amount of data to the ringbuffer, discarding the oldest
+        data as max_size is exceeded."""
+        head, tail = self._read_header()
+        while data:
+            # Amount of data to be written on this pass
+            len_to_write = min(len(data), self.max_size - head)
+
+            # Where head will be after this write
+            new_head = head + len_to_write
+
+            # In the next comparison, new_head may be self.max_size which is
+            # logically the same point as tail == 0 and must still be within
+            # the range tested.
+            unwrapped_tail = tail if tail else self.max_size
+
+            if head < unwrapped_tail <= new_head:
+                # Write will go past tail so tail needs to be pushed back
+                tail = new_head + 1  # one past head to indicate full
+                tail %= self.max_size
+                self._write_header(head, tail)
+
+            # Write the data
+            self._write_slice(head, data[:len_to_write])
+            data = data[len_to_write:]  # data now left
+
+            # Push head back
+            head = new_head
+            head %= self.max_size
+            self._write_header(head, tail)
+
+    def flush(self):
+        self.f.flush()
+
+    def close(self):
+        self.f.close()
diff -Naurp nova.orig/nova/utils.py.orig nova/nova/utils.py.orig
--- nova.orig/nova/utils.py.orig	1969-12-31 19:00:00.000000000 -0500
+++ nova/nova/utils.py.orig	2012-02-27 09:01:19.397005813 -0500
@@ -0,0 +1,1525 @@
+# vim: tabstop=4 shiftwidth=4 softtabstop=4
+
+# Copyright 2010 United States Government as represented by the
+# Administrator of the National Aeronautics and Space Administration.
+# Copyright 2011 Justin Santa Barbara
+# All Rights Reserved.
+#
+#    Licensed under the Apache License, Version 2.0 (the "License"); you may
+#    not use this file except in compliance with the License. You may obtain
+#    a copy of the License at
+#
+#         http://www.apache.org/licenses/LICENSE-2.0
+#
+#    Unless required by applicable law or agreed to in writing, software
+#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+#    License for the specific language governing permissions and limitations
+#    under the License.
+
+"""Utilities and helper functions."""
+
+import contextlib
+import datetime
+import functools
+import hashlib
+import inspect
+import itertools
+import json
+import os
+import pyclbr
+import random
+import re
+import shlex
+import socket
+import struct
+import sys
+import time
+import types
+import uuid
+import warnings
+from xml.sax import saxutils
+
+from eventlet import event
+from eventlet import greenthread
+from eventlet import semaphore
+from eventlet.green import subprocess
+import iso8601
+import lockfile
+import netaddr
+
+from nova import exception
+from nova import flags
+from nova import log as logging
+from nova.openstack.common import cfg
+
+
+LOG = logging.getLogger(__name__)
+ISO_TIME_FORMAT = "%Y-%m-%dT%H:%M:%S"
+PERFECT_TIME_FORMAT = "%Y-%m-%dT%H:%M:%S.%f"
+FLAGS = flags.FLAGS
+
+FLAGS.register_opt(
+    cfg.BoolOpt('disable_process_locking', default=False,
+                help='Whether to disable inter-process locks'))
+
+
+def import_class(import_str):
+    """Returns a class from a string including module and class."""
+    mod_str, _sep, class_str = import_str.rpartition('.')
+    try:
+        __import__(mod_str)
+        return getattr(sys.modules[mod_str], class_str)
+    except (ImportError, ValueError, AttributeError), exc:
+        LOG.debug(_('Inner Exception: %s'), exc)
+        raise exception.ClassNotFound(class_name=class_str, exception=exc)
+
+
+def import_object(import_str):
+    """Returns an object including a module or module and class."""
+    try:
+        __import__(import_str)
+        return sys.modules[import_str]
+    except ImportError:
+        cls = import_class(import_str)
+        return cls()
+
+
+def find_config(config_path):
+    """Find a configuration file using the given hint.
+
+    :param config_path: Full or relative path to the config.
+    :returns: Full path of the config, if it exists.
+    :raises: `nova.exception.ConfigNotFound`
+
+    """
+    possible_locations = [
+        config_path,
+        os.path.join(FLAGS.state_path, "etc", "nova", config_path),
+        os.path.join(FLAGS.state_path, "etc", config_path),
+        os.path.join(FLAGS.state_path, config_path),
+        "/etc/nova/%s" % config_path,
+    ]
+
+    for path in possible_locations:
+        if os.path.exists(path):
+            return os.path.abspath(path)
+
+    raise exception.ConfigNotFound(path=os.path.abspath(config_path))
+
+
+def vpn_ping(address, port, timeout=0.05, session_id=None):
+    """Sends a vpn negotiation packet and returns the server session.
+
+    Returns False on a failure. Basic packet structure is below.
+
+    Client packet (14 bytes)::
+     0 1      8 9  13
+    +-+--------+-----+
+    |x| cli_id |?????|
+    +-+--------+-----+
+    x = packet identifier 0x38
+    cli_id = 64 bit identifier
+    ? = unknown, probably flags/padding
+
+    Server packet (26 bytes)::
+     0 1      8 9  13 14    21 2225
+    +-+--------+-----+--------+----+
+    |x| srv_id |?????| cli_id |????|
+    +-+--------+-----+--------+----+
+    x = packet identifier 0x40
+    cli_id = 64 bit identifier
+    ? = unknown, probably flags/padding
+    bit 9 was 1 and the rest were 0 in testing
+
+    """
+    if session_id is None:
+        session_id = random.randint(0, 0xffffffffffffffff)
+    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
+    data = struct.pack('!BQxxxxx', 0x38, session_id)
+    sock.sendto(data, (address, port))
+    sock.settimeout(timeout)
+    try:
+        received = sock.recv(2048)
+    except socket.timeout:
+        return False
+    finally:
+        sock.close()
+    fmt = '!BQxxxxxQxxxx'
+    if len(received) != struct.calcsize(fmt):
+        print struct.calcsize(fmt)
+        return False
+    (identifier, server_sess, client_sess) = struct.unpack(fmt, received)
+    if identifier == 0x40 and client_sess == session_id:
+        return server_sess
+
+
+def fetchfile(url, target):
+    LOG.debug(_('Fetching %s') % url)
+    execute('curl', '--fail', url, '-o', target)
+
+
+def execute(*cmd, **kwargs):
+    """
+    Helper method to execute command with optional retry.
+
+    :cmd                Passed to subprocess.Popen.
+    :process_input      Send to opened process.
+    :check_exit_code    Single bool, int, or list of allowed exit codes.
+                        Defaults to [0].  Raise exception.ProcessExecutionError
+                        unless program exits with one of these code.
+    :delay_on_retry     True | False. Defaults to True. If set to True, wait a
+                        short amount of time before retrying.
+    :attempts           How many times to retry cmd.
+    :run_as_root        True | False. Defaults to False. If set to True,
+                        the command is prefixed by the command specified
+                        in the root_helper FLAG.
+
+    :raises exception.Error on receiving unknown arguments
+    :raises exception.ProcessExecutionError
+
+    :returns a tuple, (stdout, stderr) from the spawned process, or None if
+             the command fails.
+    """
+
+    process_input = kwargs.pop('process_input', None)
+    check_exit_code = kwargs.pop('check_exit_code', [0])
+    ignore_exit_code = False
+    if isinstance(check_exit_code, bool):
+        ignore_exit_code = not check_exit_code
+        check_exit_code = [0]
+    elif isinstance(check_exit_code, int):
+        check_exit_code = [check_exit_code]
+    delay_on_retry = kwargs.pop('delay_on_retry', True)
+    attempts = kwargs.pop('attempts', 1)
+    run_as_root = kwargs.pop('run_as_root', False)
+    shell = kwargs.pop('shell', False)
+
+    if len(kwargs):
+        raise exception.Error(_('Got unknown keyword args '
+                                'to utils.execute: %r') % kwargs)
+
+    if run_as_root:
+        cmd = shlex.split(FLAGS.root_helper) + list(cmd)
+    cmd = map(str, cmd)
+
+    while attempts > 0:
+        attempts -= 1
+        try:
+            LOG.debug(_('Running cmd (subprocess): %s'), ' '.join(cmd))
+            _PIPE = subprocess.PIPE  # pylint: disable=E1101
+            obj = subprocess.Popen(cmd,
+                                   stdin=_PIPE,
+                                   stdout=_PIPE,
+                                   stderr=_PIPE,
+                                   close_fds=True,
+                                   shell=shell)
+            result = None
+            if process_input is not None:
+                result = obj.communicate(process_input)
+            else:
+                result = obj.communicate()
+            obj.stdin.close()  # pylint: disable=E1101
+            _returncode = obj.returncode  # pylint: disable=E1101
+            if _returncode:
+                LOG.debug(_('Result was %s') % _returncode)
+                if not ignore_exit_code and _returncode not in check_exit_code:
+                    (stdout, stderr) = result
+                    raise exception.ProcessExecutionError(
+                            exit_code=_returncode,
+                            stdout=stdout,
+                            stderr=stderr,
+                            cmd=' '.join(cmd))
+            return result
+        except exception.ProcessExecutionError:
+            if not attempts:
+                raise
+            else:
+                LOG.debug(_('%r failed. Retrying.'), cmd)
+                if delay_on_retry:
+                    greenthread.sleep(random.randint(20, 200) / 100.0)
+        finally:
+            # NOTE(termie): this appears to be necessary to let the subprocess
+            #               call clean something up in between calls, without
+            #               it two execute calls in a row hangs the second one
+            greenthread.sleep(0)
+
+
+def trycmd(*args, **kwargs):
+    """
+    A wrapper around execute() to more easily handle warnings and errors.
+
+    Returns an (out, err) tuple of strings containing the output of
+    the command's stdout and stderr.  If 'err' is not empty then the
+    command can be considered to have failed.
+
+    :discard_warnings   True | False. Defaults to False. If set to True,
+                        then for succeeding commands, stderr is cleared
+
+    """
+    discard_warnings = kwargs.pop('discard_warnings', False)
+
+    try:
+        out, err = execute(*args, **kwargs)
+        failed = False
+    except exception.ProcessExecutionError, exn:
+        out, err = '', str(exn)
+        LOG.debug(err)
+        failed = True
+
+    if not failed and discard_warnings and err:
+        # Handle commands that output to stderr but otherwise succeed
+        LOG.debug(err)
+        err = ''
+
+    return out, err
+
+
+def ssh_execute(ssh, cmd, process_input=None,
+                addl_env=None, check_exit_code=True):
+    LOG.debug(_('Running cmd (SSH): %s'), ' '.join(cmd))
+    if addl_env:
+        raise exception.Error(_('Environment not supported over SSH'))
+
+    if process_input:
+        # This is (probably) fixable if we need it...
+        raise exception.Error(_('process_input not supported over SSH'))
+
+    stdin_stream, stdout_stream, stderr_stream = ssh.exec_command(cmd)
+    channel = stdout_stream.channel
+
+    #stdin.write('process_input would go here')
+    #stdin.flush()
+
+    # NOTE(justinsb): This seems suspicious...
+    # ...other SSH clients have buffering issues with this approach
+    stdout = stdout_stream.read()
+    stderr = stderr_stream.read()
+    stdin_stream.close()
+
+    exit_status = channel.recv_exit_status()
+
+    # exit_status == -1 if no exit code was returned
+    if exit_status != -1:
+        LOG.debug(_('Result was %s') % exit_status)
+        if check_exit_code and exit_status != 0:
+            raise exception.ProcessExecutionError(exit_code=exit_status,
+                                                  stdout=stdout,
+                                                  stderr=stderr,
+                                                  cmd=' '.join(cmd))
+
+    return (stdout, stderr)
+
+
+def abspath(s):
+    return os.path.join(os.path.dirname(__file__), s)
+
+
+def novadir():
+    import nova
+    return os.path.abspath(nova.__file__).split('nova/__init__.py')[0]
+
+
+def default_flagfile(filename='nova.conf', args=None):
+    if args is None:
+        args = sys.argv
+    for arg in args:
+        if arg.find('flagfile') != -1:
+            return arg[arg.index('flagfile') + len('flagfile') + 1:]
+    else:
+        if not os.path.isabs(filename):
+            # turn relative filename into an absolute path
+            script_dir = os.path.dirname(inspect.stack()[-1][1])
+            filename = os.path.abspath(os.path.join(script_dir, filename))
+        if not os.path.exists(filename):
+            filename = "./nova.conf"
+            if not os.path.exists(filename):
+                filename = '/etc/nova/nova.conf'
+        if os.path.exists(filename):
+            flagfile = '--flagfile=%s' % filename
+            args.insert(1, flagfile)
+            return filename
+
+
+def debug(arg):
+    LOG.debug(_('debug in callback: %s'), arg)
+    return arg
+
+
+def generate_uid(topic, size=8):
+    characters = '01234567890abcdefghijklmnopqrstuvwxyz'
+    choices = [random.choice(characters) for x in xrange(size)]
+    return '%s-%s' % (topic, ''.join(choices))
+
+
+# Default symbols to use for passwords. Avoids visually confusing characters.
+# ~6 bits per symbol
+DEFAULT_PASSWORD_SYMBOLS = ('23456789',  # Removed: 0,1
+                            'ABCDEFGHJKLMNPQRSTUVWXYZ',   # Removed: I, O
+                            'abcdefghijkmnopqrstuvwxyz')  # Removed: l
+
+
+# ~5 bits per symbol
+EASIER_PASSWORD_SYMBOLS = ('23456789',  # Removed: 0, 1
+                           'ABCDEFGHJKLMNPQRSTUVWXYZ')  # Removed: I, O
+
+
+def current_audit_period(unit=None):
+    if not unit:
+        unit = FLAGS.instance_usage_audit_period
+    rightnow = utcnow()
+    if unit not in ('month', 'day', 'year', 'hour'):
+        raise ValueError('Time period must be hour, day, month or year')
+    n = 1  # we are currently only using multiples of 1 unit (mdragon)
+    if unit == 'month':
+        year = rightnow.year - (n // 12)
+        n = n % 12
+        if n >= rightnow.month:
+            year -= 1
+            month = 12 + (rightnow.month - n)
+        else:
+            month = rightnow.month - n
+        begin = datetime.datetime(day=1, month=month, year=year)
+        end = datetime.datetime(day=1,
+                                month=rightnow.month,
+                                year=rightnow.year)
+
+    elif unit == 'year':
+        begin = datetime.datetime(day=1, month=1, year=rightnow.year - n)
+        end = datetime.datetime(day=1, month=1, year=rightnow.year)
+
+    elif unit == 'day':
+        b = rightnow - datetime.timedelta(days=n)
+        begin = datetime.datetime(day=b.day, month=b.month, year=b.year)
+        end = datetime.datetime(day=rightnow.day,
+                               month=rightnow.month,
+                               year=rightnow.year)
+    elif unit == 'hour':
+        end = rightnow.replace(minute=0, second=0, microsecond=0)
+        begin = end - datetime.timedelta(hours=n)
+
+    return (begin, end)
+
+
+def usage_from_instance(instance_ref, network_info=None, **kw):
+    image_ref_url = "%s/images/%s" % (generate_glance_url(),
+            instance_ref['image_ref'])
+
+    usage_info = dict(
+          tenant_id=instance_ref['project_id'],
+          user_id=instance_ref['user_id'],
+          instance_id=instance_ref['uuid'],
+          instance_type=instance_ref['instance_type']['name'],
+          instance_type_id=instance_ref['instance_type_id'],
+          memory_mb=instance_ref['memory_mb'],
+          disk_gb=instance_ref['root_gb'] + instance_ref['ephemeral_gb'],
+          display_name=instance_ref['display_name'],
+          created_at=str(instance_ref['created_at']),
+          launched_at=str(instance_ref['launched_at'])
+                      if instance_ref['launched_at'] else '',
+          image_ref_url=image_ref_url,
+          state=instance_ref['vm_state'],
+          state_description=instance_ref['task_state']
+                            if instance_ref['task_state'] else '')
+
+    if network_info is not None:
+        usage_info['fixed_ips'] = network_info.fixed_ips()
+
+    usage_info.update(kw)
+    return usage_info
+
+
+def generate_password(length=20, symbolgroups=DEFAULT_PASSWORD_SYMBOLS):
+    """Generate a random password from the supplied symbol groups.
+
+    At least one symbol from each group will be included. Unpredictable
+    results if length is less than the number of symbol groups.
+
+    Believed to be reasonably secure (with a reasonable password length!)
+
+    """
+    r = random.SystemRandom()
+
+    # NOTE(jerdfelt): Some password policies require at least one character
+    # from each group of symbols, so start off with one random character
+    # from each symbol group
+    password = [r.choice(s) for s in symbolgroups]
+    # If length < len(symbolgroups), the leading characters will only
+    # be from the first length groups. Try our best to not be predictable
+    # by shuffling and then truncating.
+    r.shuffle(password)
+    password = password[:length]
+    length -= len(password)
+
+    # then fill with random characters from all symbol groups
+    symbols = ''.join(symbolgroups)
+    password.extend([r.choice(symbols) for _i in xrange(length)])
+
+    # finally shuffle to ensure first x characters aren't from a
+    # predictable group
+    r.shuffle(password)
+
+    return ''.join(password)
+
+
+def last_octet(address):
+    return int(address.split('.')[-1])
+
+
+def get_my_linklocal(interface):
+    try:
+        if_str = execute('ip', '-f', 'inet6', '-o', 'addr', 'show', interface)
+        condition = '\s+inet6\s+([0-9a-f:]+)/\d+\s+scope\s+link'
+        links = [re.search(condition, x) for x in if_str[0].split('\n')]
+        address = [w.group(1) for w in links if w is not None]
+        if address[0] is not None:
+            return address[0]
+        else:
+            raise exception.Error(_('Link Local address is not found.:%s')
+                                  % if_str)
+    except Exception as ex:
+        raise exception.Error(_("Couldn't get Link Local IP of %(interface)s"
+                                " :%(ex)s") % locals())
+
+
+def utcnow():
+    """Overridable version of utils.utcnow."""
+    if utcnow.override_time:
+        return utcnow.override_time
+    return datetime.datetime.utcnow()
+
+
+utcnow.override_time = None
+
+
+def is_older_than(before, seconds):
+    """Return True if before is older than seconds."""
+    return utcnow() - before > datetime.timedelta(seconds=seconds)
+
+
+def utcnow_ts():
+    """Timestamp version of our utcnow function."""
+    return time.mktime(utcnow().timetuple())
+
+
+def set_time_override(override_time=datetime.datetime.utcnow()):
+    """Override utils.utcnow to return a constant time."""
+    utcnow.override_time = override_time
+
+
+def advance_time_delta(timedelta):
+    """Advance overriden time using a datetime.timedelta."""
+    assert(not utcnow.override_time is None)
+    utcnow.override_time += timedelta
+
+
+def advance_time_seconds(seconds):
+    """Advance overriden time by seconds."""
+    advance_time_delta(datetime.timedelta(0, seconds))
+
+
+def clear_time_override():
+    """Remove the overridden time."""
+    utcnow.override_time = None
+
+
+def strtime(at=None, fmt=PERFECT_TIME_FORMAT):
+    """Returns formatted utcnow."""
+    if not at:
+        at = utcnow()
+    return at.strftime(fmt)
+
+
+def parse_strtime(timestr, fmt=PERFECT_TIME_FORMAT):
+    """Turn a formatted time back into a datetime."""
+    return datetime.datetime.strptime(timestr, fmt)
+
+
+def isotime(at=None):
+    """Stringify time in ISO 8601 format"""
+    if not at:
+        at = datetime.datetime.utcnow()
+    str = at.strftime(ISO_TIME_FORMAT)
+    tz = at.tzinfo.tzname(None) if at.tzinfo else 'UTC'
+    str += ('Z' if tz == 'UTC' else tz)
+    return str
+
+
+def parse_isotime(timestr):
+    """Turn an iso formatted time back into a datetime."""
+    try:
+        return iso8601.parse_date(timestr)
+    except (iso8601.ParseError, TypeError) as e:
+        raise ValueError(e.message)
+
+
+def normalize_time(timestamp):
+    """Normalize time in arbitrary timezone to UTC"""
+    offset = timestamp.utcoffset()
+    return timestamp.replace(tzinfo=None) - offset if offset else timestamp
+
+
+def parse_mailmap(mailmap='.mailmap'):
+    mapping = {}
+    if os.path.exists(mailmap):
+        fp = open(mailmap, 'r')
+        for l in fp:
+            l = l.strip()
+            if not l.startswith('#') and ' ' in l:
+                canonical_email, alias = l.split(' ')
+                mapping[alias.lower()] = canonical_email.lower()
+    return mapping
+
+
+def str_dict_replace(s, mapping):
+    for s1, s2 in mapping.iteritems():
+        s = s.replace(s1, s2)
+    return s
+
+
+class LazyPluggable(object):
+    """A pluggable backend loaded lazily based on some value."""
+
+    def __init__(self, pivot, **backends):
+        self.__backends = backends
+        self.__pivot = pivot
+        self.__backend = None
+
+    def __get_backend(self):
+        if not self.__backend:
+            backend_name = FLAGS[self.__pivot]
+            if backend_name not in self.__backends:
+                raise exception.Error(_('Invalid backend: %s') % backend_name)
+
+            backend = self.__backends[backend_name]
+            if isinstance(backend, tuple):
+                name = backend[0]
+                fromlist = backend[1]
+            else:
+                name = backend
+                fromlist = backend
+
+            self.__backend = __import__(name, None, None, fromlist)
+            LOG.debug(_('backend %s'), self.__backend)
+        return self.__backend
+
+    def __getattr__(self, key):
+        backend = self.__get_backend()
+        return getattr(backend, key)
+
+
+class LoopingCallDone(Exception):
+    """Exception to break out and stop a LoopingCall.
+
+    The poll-function passed to LoopingCall can raise this exception to
+    break out of the loop normally. This is somewhat analogous to
+    StopIteration.
+
+    An optional return-value can be included as the argument to the exception;
+    this return-value will be returned by LoopingCall.wait()
+
+    """
+
+    def __init__(self, retvalue=True):
+        """:param retvalue: Value that LoopingCall.wait() should return."""
+        self.retvalue = retvalue
+
+
+class LoopingCall(object):
+    def __init__(self, f=None, *args, **kw):
+        self.args = args
+        self.kw = kw
+        self.f = f
+        self._running = False
+
+    def start(self, interval, now=True):
+        self._running = True
+        done = event.Event()
+
+        def _inner():
+            if not now:
+                greenthread.sleep(interval)
+            try:
+                while self._running:
+                    self.f(*self.args, **self.kw)
+                    if not self._running:
+                        break
+                    greenthread.sleep(interval)
+            except LoopingCallDone, e:
+                self.stop()
+                done.send(e.retvalue)
+            except Exception:
+                LOG.exception(_('in looping call'))
+                done.send_exception(*sys.exc_info())
+                return
+            else:
+                done.send(True)
+
+        self.done = done
+
+        greenthread.spawn(_inner)
+        return self.done
+
+    def stop(self):
+        self._running = False
+
+    def wait(self):
+        return self.done.wait()
+
+
+def xhtml_escape(value):
+    """Escapes a string so it is valid within XML or XHTML.
+
+    """
+    return saxutils.escape(value, {'"': '&quot;', "'": '&apos;'})
+
+
+def utf8(value):
+    """Try to turn a string into utf-8 if possible.
+
+    Code is directly from the utf8 function in
+    http://github.com/facebook/tornado/blob/master/tornado/escape.py
+
+    """
+    if isinstance(value, unicode):
+        return value.encode('utf-8')
+    assert isinstance(value, str)
+    return value
+
+
+def to_primitive(value, convert_instances=False, level=0):
+    """Convert a complex object into primitives.
+
+    Handy for JSON serialization. We can optionally handle instances,
+    but since this is a recursive function, we could have cyclical
+    data structures.
+
+    To handle cyclical data structures we could track the actual objects
+    visited in a set, but not all objects are hashable. Instead we just
+    track the depth of the object inspections and don't go too deep.
+
+    Therefore, convert_instances=True is lossy ... be aware.
+
+    """
+    nasty = [inspect.ismodule, inspect.isclass, inspect.ismethod,
+             inspect.isfunction, inspect.isgeneratorfunction,
+             inspect.isgenerator, inspect.istraceback, inspect.isframe,
+             inspect.iscode, inspect.isbuiltin, inspect.isroutine,
+             inspect.isabstract]
+    for test in nasty:
+        if test(value):
+            return unicode(value)
+
+    # value of itertools.count doesn't get caught by inspects
+    # above and results in infinite loop when list(value) is called.
+    if type(value) == itertools.count:
+        return unicode(value)
+
+    # FIXME(vish): Workaround for LP bug 852095. Without this workaround,
+    #              tests that raise an exception in a mocked method that
+    #              has a @wrap_exception with a notifier will fail. If
+    #              we up the dependency to 0.5.4 (when it is released) we
+    #              can remove this workaround.
+    if getattr(value, '__module__', None) == 'mox':
+        return 'mock'
+
+    if level > 3:
+        return '?'
+
+    # The try block may not be necessary after the class check above,
+    # but just in case ...
+    try:
+        if isinstance(value, (list, tuple)):
+            o = []
+            for v in value:
+                o.append(to_primitive(v, convert_instances=convert_instances,
+                                      level=level))
+            return o
+        elif isinstance(value, dict):
+            o = {}
+            for k, v in value.iteritems():
+                o[k] = to_primitive(v, convert_instances=convert_instances,
+                                    level=level)
+            return o
+        elif isinstance(value, datetime.datetime):
+            return str(value)
+        elif hasattr(value, 'iteritems'):
+            return to_primitive(dict(value.iteritems()),
+                                convert_instances=convert_instances,
+                                level=level)
+        elif hasattr(value, '__iter__'):
+            return to_primitive(list(value), level)
+        elif convert_instances and hasattr(value, '__dict__'):
+            # Likely an instance of something. Watch for cycles.
+            # Ignore class member vars.
+            return to_primitive(value.__dict__,
+                                convert_instances=convert_instances,
+                                level=level + 1)
+        else:
+            return value
+    except TypeError, e:
+        # Class objects are tricky since they may define something like
+        # __iter__ defined but it isn't callable as list().
+        return unicode(value)
+
+
+def dumps(value):
+    try:
+        return json.dumps(value)
+    except TypeError:
+        pass
+    return json.dumps(to_primitive(value))
+
+
+def loads(s):
+    return json.loads(s)
+
+
+try:
+    import anyjson
+except ImportError:
+    pass
+else:
+    anyjson._modules.append(("nova.utils", "dumps", TypeError,
+                                           "loads", ValueError))
+    anyjson.force_implementation("nova.utils")
+
+
+_semaphores = {}
+
+
+def synchronized(name, external=False):
+    """Synchronization decorator.
+
+    Decorating a method like so:
+    @synchronized('mylock')
+    def foo(self, *args):
+       ...
+
+    ensures that only one thread will execute the bar method at a time.
+
+    Different methods can share the same lock:
+    @synchronized('mylock')
+    def foo(self, *args):
+       ...
+
+    @synchronized('mylock')
+    def bar(self, *args):
+       ...
+
+    This way only one of either foo or bar can be executing at a time.
+
+    The external keyword argument denotes whether this lock should work across
+    multiple processes. This means that if two different workers both run a
+    a method decorated with @synchronized('mylock', external=True), only one
+    of them will execute at a time.
+
+    """
+
+    def wrap(f):
+        @functools.wraps(f)
+        def inner(*args, **kwargs):
+            # NOTE(soren): If we ever go natively threaded, this will be racy.
+            #              See http://stackoverflow.com/questions/5390569/dyn
+            #              amically-allocating-and-destroying-mutexes
+            if name not in _semaphores:
+                _semaphores[name] = semaphore.Semaphore()
+            sem = _semaphores[name]
+            LOG.debug(_('Attempting to grab semaphore "%(lock)s" for method '
+                        '"%(method)s"...' % {'lock': name,
+                                             'method': f.__name__}))
+            with sem:
+                LOG.debug(_('Got semaphore "%(lock)s" for method '
+                            '"%(method)s"...' % {'lock': name,
+                                                 'method': f.__name__}))
+                if external and not FLAGS.disable_process_locking:
+                    LOG.debug(_('Attempting to grab file lock "%(lock)s" for '
+                                'method "%(method)s"...' %
+                                {'lock': name, 'method': f.__name__}))
+                    lock_file_path = os.path.join(FLAGS.lock_path,
+                                                  'nova-%s' % name)
+                    lock = lockfile.FileLock(lock_file_path)
+                    with lock:
+                        LOG.debug(_('Got file lock "%(lock)s" for '
+                                    'method "%(method)s"...' %
+                                    {'lock': name, 'method': f.__name__}))
+                        retval = f(*args, **kwargs)
+                else:
+                    retval = f(*args, **kwargs)
+
+            # If no-one else is waiting for it, delete it.
+            # See note about possible raciness above.
+            if not sem.balance < 1:
+                del _semaphores[name]
+
+            return retval
+        return inner
+    return wrap
+
+
+def cleanup_file_locks():
+    """clean up stale locks left behind by process failures
+
+    The lockfile module, used by @synchronized, can leave stale lockfiles
+    behind after process failure. These locks can cause process hangs
+    at startup, when a process deadlocks on a lock which will never
+    be unlocked.
+
+    Intended to be called at service startup.
+
+    """
+
+    # NOTE(mikeyp) this routine incorporates some internal knowledge
+    #              from the lockfile module, and this logic really
+    #              should be part of that module.
+    #
+    # cleanup logic:
+    # 1) look for the lockfile modules's 'sentinel' files, of the form
+    #    hostname.[thread-.*]-pid, extract the pid.
+    #    if pid doesn't match a running process, delete the file since
+    #    it's from a dead process.
+    # 2) check for the actual lockfiles. if lockfile exists with linkcount
+    #    of 1, it's bogus, so delete it. A link count >= 2 indicates that
+    #    there are probably sentinels still linked to it from active
+    #    processes.  This check isn't perfect, but there is no way to
+    #    reliably tell which sentinels refer to which lock in the
+    #    lockfile implementation.
+
+    if  FLAGS.disable_process_locking:
+        return
+
+    hostname = socket.gethostname()
+    sentinel_re = hostname + r'\..*-(\d+$)'
+    lockfile_re = r'nova-.*\.lock'
+    files = os.listdir(FLAGS.lock_path)
+
+    # cleanup sentinels
+    for filename in files:
+        match = re.match(sentinel_re, filename)
+        if match is None:
+            continue
+        pid = match.group(1)
+        LOG.debug(_('Found sentinel %(filename)s for pid %(pid)s' %
+                    {'filename': filename, 'pid': pid}))
+        if not os.path.exists(os.path.join('/proc', pid)):
+            delete_if_exists(os.path.join(FLAGS.lock_path, filename))
+            LOG.debug(_('Cleaned sentinel %(filename)s for pid %(pid)s' %
+                        {'filename': filename, 'pid': pid}))
+
+    # cleanup lock files
+    for filename in files:
+        match = re.match(lockfile_re, filename)
+        if match is None:
+            continue
+        try:
+            stat_info = os.stat(os.path.join(FLAGS.lock_path, filename))
+        except OSError as (errno, strerror):
+            if errno == 2:  # doesn't exist
+                continue
+            else:
+                raise
+        msg = _('Found lockfile %(file)s with link count %(count)d' %
+                {'file': filename, 'count': stat_info.st_nlink})
+        LOG.debug(msg)
+        if stat_info.st_nlink == 1:
+            delete_if_exists(os.path.join(FLAGS.lock_path, filename))
+            msg = _('Cleaned lockfile %(file)s with link count %(count)d' %
+                    {'file': filename, 'count': stat_info.st_nlink})
+            LOG.debug(msg)
+
+
+def delete_if_exists(pathname):
+    """delete a file, but ignore file not found error"""
+
+    try:
+        os.unlink(pathname)
+    except OSError as (errno, strerror):
+        if errno == 2:  # doesn't exist
+            return
+        else:
+            raise
+
+
+def get_from_path(items, path):
+    """Returns a list of items matching the specified path.
+
+    Takes an XPath-like expression e.g. prop1/prop2/prop3, and for each item
+    in items, looks up items[prop1][prop2][prop3].  Like XPath, if any of the
+    intermediate results are lists it will treat each list item individually.
+    A 'None' in items or any child expressions will be ignored, this function
+    will not throw because of None (anywhere) in items.  The returned list
+    will contain no None values.
+
+    """
+    if path is None:
+        raise exception.Error('Invalid mini_xpath')
+
+    (first_token, sep, remainder) = path.partition('/')
+
+    if first_token == '':
+        raise exception.Error('Invalid mini_xpath')
+
+    results = []
+
+    if items is None:
+        return results
+
+    if not isinstance(items, list):
+        # Wrap single objects in a list
+        items = [items]
+
+    for item in items:
+        if item is None:
+            continue
+        get_method = getattr(item, 'get', None)
+        if get_method is None:
+            continue
+        child = get_method(first_token)
+        if child is None:
+            continue
+        if isinstance(child, list):
+            # Flatten intermediate lists
+            for x in child:
+                results.append(x)
+        else:
+            results.append(child)
+
+    if not sep:
+        # No more tokens
+        return results
+    else:
+        return get_from_path(results, remainder)
+
+
+def flatten_dict(dict_, flattened=None):
+    """Recursively flatten a nested dictionary."""
+    flattened = flattened or {}
+    for key, value in dict_.iteritems():
+        if hasattr(value, 'iteritems'):
+            flatten_dict(value, flattened)
+        else:
+            flattened[key] = value
+    return flattened
+
+
+def partition_dict(dict_, keys):
+    """Return two dicts, one with `keys` the other with everything else."""
+    intersection = {}
+    difference = {}
+    for key, value in dict_.iteritems():
+        if key in keys:
+            intersection[key] = value
+        else:
+            difference[key] = value
+    return intersection, difference
+
+
+def map_dict_keys(dict_, key_map):
+    """Return a dict in which the dictionaries keys are mapped to new keys."""
+    mapped = {}
+    for key, value in dict_.iteritems():
+        mapped_key = key_map[key] if key in key_map else key
+        mapped[mapped_key] = value
+    return mapped
+
+
+def subset_dict(dict_, keys):
+    """Return a dict that only contains a subset of keys."""
+    subset = partition_dict(dict_, keys)[0]
+    return subset
+
+
+def check_isinstance(obj, cls):
+    """Checks that obj is of type cls, and lets PyLint infer types."""
+    if isinstance(obj, cls):
+        return obj
+    raise Exception(_('Expected object of type: %s') % (str(cls)))
+    # TODO(justinsb): Can we make this better??
+    return cls()  # Ugly PyLint hack
+
+
+def parse_server_string(server_str):
+    """
+    Parses the given server_string and returns a list of host and port.
+    If it's not a combination of host part and port, the port element
+    is a null string. If the input is invalid expression, return a null
+    list.
+    """
+    try:
+        # First of all, exclude pure IPv6 address (w/o port).
+        if netaddr.valid_ipv6(server_str):
+            return (server_str, '')
+
+        # Next, check if this is IPv6 address with a port number combination.
+        if server_str.find("]:") != -1:
+            (address, port) = server_str.replace('[', '', 1).split(']:')
+            return (address, port)
+
+        # Third, check if this is a combination of an address and a port
+        if server_str.find(':') == -1:
+            return (server_str, '')
+
+        # This must be a combination of an address and a port
+        (address, port) = server_str.split(':')
+        return (address, port)
+
+    except Exception:
+        LOG.debug(_('Invalid server_string: %s' % server_str))
+        return ('', '')
+
+
+def gen_uuid():
+    return uuid.uuid4()
+
+
+def is_uuid_like(val):
+    """For our purposes, a UUID is a string in canonical form:
+
+        aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa
+    """
+    try:
+        uuid.UUID(val)
+        return True
+    except (TypeError, ValueError, AttributeError):
+        return False
+
+
+def bool_from_str(val):
+    """Convert a string representation of a bool into a bool value"""
+
+    if not val:
+        return False
+    try:
+        return True if int(val) else False
+    except ValueError:
+        return val.lower() == 'true'
+
+
+def is_valid_ipv4(address):
+    """valid the address strictly as per format xxx.xxx.xxx.xxx.
+    where xxx is a value between 0 and 255.
+    """
+    parts = address.split(".")
+    if len(parts) != 4:
+        return False
+    for item in parts:
+        try:
+            if not 0 <= int(item) <= 255:
+                return False
+        except ValueError:
+            return False
+    return True
+
+
+def is_valid_cidr(address):
+    """Check if the provided ipv4 or ipv6 address is a valid
+    CIDR address or not"""
+    try:
+        # Validate the correct CIDR Address
+        netaddr.IPNetwork(address)
+    except netaddr.core.AddrFormatError:
+        return False
+
+    # Prior validation partially verify /xx part
+    # Verify it here
+    ip_segment = address.split('/')
+
+    if (len(ip_segment) <= 1 or
+        ip_segment[1] == ''):
+        return False
+
+    return True
+
+
+def monkey_patch():
+    """  If the Flags.monkey_patch set as True,
+    this function patches a decorator
+    for all functions in specified modules.
+    You can set decorators for each modules
+    using FLAGS.monkey_patch_modules.
+    The format is "Module path:Decorator function".
+    Example: 'nova.api.ec2.cloud:nova.notifier.api.notify_decorator'
+
+    Parameters of the decorator is as follows.
+    (See nova.notifier.api.notify_decorator)
+
+    name - name of the function
+    function - object of the function
+    """
+    # If FLAGS.monkey_patch is not True, this function do nothing.
+    if not FLAGS.monkey_patch:
+        return
+    # Get list of modules and decorators
+    for module_and_decorator in FLAGS.monkey_patch_modules:
+        module, decorator_name = module_and_decorator.split(':')
+        # import decorator function
+        decorator = import_class(decorator_name)
+        __import__(module)
+        # Retrieve module information using pyclbr
+        module_data = pyclbr.readmodule_ex(module)
+        for key in module_data.keys():
+            # set the decorator for the class methods
+            if isinstance(module_data[key], pyclbr.Class):
+                clz = import_class("%s.%s" % (module, key))
+                for method, func in inspect.getmembers(clz, inspect.ismethod):
+                    setattr(clz, method,
+                        decorator("%s.%s.%s" % (module, key, method), func))
+            # set the decorator for the function
+            if isinstance(module_data[key], pyclbr.Function):
+                func = import_class("%s.%s" % (module, key))
+                setattr(sys.modules[module], key,
+                    decorator("%s.%s" % (module, key), func))
+
+
+def convert_to_list_dict(lst, label):
+    """Convert a value or list into a list of dicts"""
+    if not lst:
+        return None
+    if not isinstance(lst, list):
+        lst = [lst]
+    return [{label: x} for x in lst]
+
+
+def timefunc(func):
+    """Decorator that logs how long a particular function took to execute"""
+    @functools.wraps(func)
+    def inner(*args, **kwargs):
+        start_time = time.time()
+        try:
+            return func(*args, **kwargs)
+        finally:
+            total_time = time.time() - start_time
+            LOG.debug(_("timefunc: '%(name)s' took %(total_time).2f secs") %
+                      dict(name=func.__name__, total_time=total_time))
+    return inner
+
+
+def generate_glance_url():
+    """Generate the URL to glance."""
+    # TODO(jk0): This will eventually need to take SSL into consideration
+    # when supported in glance.
+    return "http://%s:%d" % (FLAGS.glance_host, FLAGS.glance_port)
+
+
+@contextlib.contextmanager
+def save_and_reraise_exception():
+    """Save current exception, run some code and then re-raise.
+
+    In some cases the exception context can be cleared, resulting in None
+    being attempted to be reraised after an exception handler is run. This
+    can happen when eventlet switches greenthreads or when running an
+    exception handler, code raises and catches and exception. In both
+    cases the exception context will be cleared.
+
+    To work around this, we save the exception state, run handler code, and
+    then re-raise the original exception. If another exception occurs, the
+    saved exception is logged and the new exception is reraised.
+    """
+    type_, value, traceback = sys.exc_info()
+    try:
+        yield
+    except Exception:
+        # NOTE(jkoelker): Using LOG.error here since it accepts exc_info
+        #                 as a kwargs.
+        LOG.error(_('Original exception being dropped'),
+                  exc_info=(type_, value, traceback))
+        raise
+    raise type_, value, traceback
+
+
+@contextlib.contextmanager
+def logging_error(message):
+    """Catches exception, write message to the log, re-raise.
+    This is a common refinement of save_and_reraise that writes a specific
+    message to the log.
+    """
+    try:
+        yield
+    except Exception as error:
+        with save_and_reraise_exception():
+            LOG.exception(message)
+
+
+def make_dev_path(dev, partition=None, base='/dev'):
+    """Return a path to a particular device.
+
+    >>> make_dev_path('xvdc')
+    /dev/xvdc
+
+    >>> make_dev_path('xvdc', 1)
+    /dev/xvdc1
+    """
+    path = os.path.join(base, dev)
+    if partition:
+        path += str(partition)
+    return path
+
+
+def total_seconds(td):
+    """Local total_seconds implementation for compatibility with python 2.6"""
+    if hasattr(td, 'total_seconds'):
+        return td.total_seconds()
+    else:
+        return ((td.days * 86400 + td.seconds) * 10 ** 6 +
+                td.microseconds) / 10.0 ** 6
+
+
+def sanitize_hostname(hostname):
+    """Return a hostname which conforms to RFC-952 and RFC-1123 specs."""
+    if isinstance(hostname, unicode):
+        hostname = hostname.encode('latin-1', 'ignore')
+
+    hostname = re.sub('[ _]', '-', hostname)
+    hostname = re.sub('[^\w.-]+', '', hostname)
+    hostname = hostname.lower()
+    hostname = hostname.strip('.-')
+
+    return hostname
+
+
+def read_cached_file(filename, cache_info, reload_func=None):
+    """Read from a file if it has been modified.
+
+    :param cache_info: dictionary to hold opaque cache.
+    :param reload_func: optional function to be called with data when
+                        file is reloaded due to a modification.
+
+    :returns: data from file
+
+    """
+    mtime = os.path.getmtime(filename)
+    if not cache_info or mtime != cache_info.get('mtime'):
+        with open(filename) as fap:
+            cache_info['data'] = fap.read()
+        cache_info['mtime'] = mtime
+        if reload_func:
+            reload_func(cache_info['data'])
+    return cache_info['data']
+
+
+def hash_file(file_like_object):
+    """Generate a hash for the contents of a file."""
+    checksum = hashlib.sha1()
+    any(map(checksum.update, iter(lambda: file_like_object.read(32768), '')))
+    return checksum.hexdigest()
+
+
+@contextlib.contextmanager
+def temporary_mutation(obj, **kwargs):
+    """Temporarily set the attr on a particular object to a given value then
+    revert when finished.
+
+    One use of this is to temporarily set the read_deleted flag on a context
+    object:
+
+        with temporary_mutation(context, read_deleted="yes"):
+            do_something_that_needed_deleted_objects()
+    """
+    NOT_PRESENT = object()
+
+    old_values = {}
+    for attr, new_value in kwargs.items():
+        old_values[attr] = getattr(obj, attr, NOT_PRESENT)
+        setattr(obj, attr, new_value)
+
+    try:
+        yield
+    finally:
+        for attr, old_value in old_values.items():
+            if old_value is NOT_PRESENT:
+                del obj[attr]
+            else:
+                setattr(obj, attr, old_value)
+
+
+def warn_deprecated_class(cls, msg):
+    """
+    Issues a warning to indicate that the given class is deprecated.
+    If a message is given, it is appended to the deprecation warning.
+    """
+
+    fullname = '%s.%s' % (cls.__module__, cls.__name__)
+    if msg:
+        fullmsg = _("Class %(fullname)s is deprecated: %(msg)s")
+    else:
+        fullmsg = _("Class %(fullname)s is deprecated")
+
+    # Issue the warning
+    warnings.warn(fullmsg % locals(), DeprecationWarning, stacklevel=3)
+
+
+def warn_deprecated_function(func, msg):
+    """
+    Issues a warning to indicate that the given function is
+    deprecated.  If a message is given, it is appended to the
+    deprecation warning.
+    """
+
+    name = func.__name__
+
+    # Find the function's definition
+    sourcefile = inspect.getsourcefile(func)
+
+    # Find the line number, if possible
+    if inspect.ismethod(func):
+        code = func.im_func.func_code
+    else:
+        code = func.func_code
+    lineno = getattr(code, 'co_firstlineno', None)
+
+    if lineno is None:
+        location = sourcefile
+    else:
+        location = "%s:%d" % (sourcefile, lineno)
+
+    # Build up the message
+    if msg:
+        fullmsg = _("Function %(name)s in %(location)s is deprecated: %(msg)s")
+    else:
+        fullmsg = _("Function %(name)s in %(location)s is deprecated")
+
+    # Issue the warning
+    warnings.warn(fullmsg % locals(), DeprecationWarning, stacklevel=3)
+
+
+def _stubout(klass, message):
+    """
+    Scans a class and generates wrapping stubs for __new__() and every
+    class and static method.  Returns a dictionary which can be passed
+    to type() to generate a wrapping class.
+    """
+
+    overrides = {}
+
+    def makestub_class(name, func):
+        """
+        Create a stub for wrapping class methods.
+        """
+
+        def stub(cls, *args, **kwargs):
+            warn_deprecated_class(klass, message)
+            return func(*args, **kwargs)
+
+        # Overwrite the stub's name
+        stub.__name__ = name
+        stub.func_name = name
+
+        return classmethod(stub)
+
+    def makestub_static(name, func):
+        """
+        Create a stub for wrapping static methods.
+        """
+
+        def stub(*args, **kwargs):
+            warn_deprecated_class(klass, message)
+            return func(*args, **kwargs)
+
+        # Overwrite the stub's name
+        stub.__name__ = name
+        stub.func_name = name
+
+        return staticmethod(stub)
+
+    for name, kind, _klass, _obj in inspect.classify_class_attrs(klass):
+        # We're only interested in __new__(), class methods, and
+        # static methods...
+        if (name != '__new__' and
+            kind not in ('class method', 'static method')):
+            continue
+
+        # Get the function...
+        func = getattr(klass, name)
+
+        # Override it in the class
+        if kind == 'class method':
+            stub = makestub_class(name, func)
+        elif kind == 'static method' or name == '__new__':
+            stub = makestub_static(name, func)
+
+        # Save it in the overrides dictionary...
+        overrides[name] = stub
+
+    # Apply the overrides
+    for name, stub in overrides.items():
+        setattr(klass, name, stub)
+
+
+def deprecated(message=''):
+    """
+    Marks a function, class, or method as being deprecated.  For
+    functions and methods, emits a warning each time the function or
+    method is called.  For classes, generates a new subclass which
+    will emit a warning each time the class is instantiated, or each
+    time any class or static method is called.
+
+    If a message is passed to the decorator, that message will be
+    appended to the emitted warning.  This may be used to suggest an
+    alternate way of achieving the desired effect, or to explain why
+    the function, class, or method is deprecated.
+    """
+
+    def decorator(f_or_c):
+        # Make sure we can deprecate it...
+        if not callable(f_or_c) or isinstance(f_or_c, types.ClassType):
+            warnings.warn("Cannot mark object %r as deprecated" % f_or_c,
+                          DeprecationWarning, stacklevel=2)
+            return f_or_c
+
+        # If we're deprecating a class, create a subclass of it and
+        # stub out all the class and static methods
+        if inspect.isclass(f_or_c):
+            klass = f_or_c
+            _stubout(klass, message)
+            return klass
+
+        # OK, it's a function; use a traditional wrapper...
+        func = f_or_c
+
+        @functools.wraps(func)
+        def wrapper(*args, **kwargs):
+            warn_deprecated_function(func, message)
+
+            return func(*args, **kwargs)
+
+        return wrapper
+    return decorator
+
+
+def _showwarning(message, category, filename, lineno, file=None, line=None):
+    """
+    Redirect warnings into logging.
+    """
+
+    fmtmsg = warnings.formatwarning(message, category, filename, lineno, line)
+    LOG.warning(fmtmsg)
+
+
+# Install our warnings handler
+warnings.showwarning = _showwarning
+
+
+def service_is_up(service):
+    """Check whether a service is up based on last heartbeat."""
+    last_heartbeat = service['updated_at'] or service['created_at']
+    # Timestamps in DB are UTC.
+    elapsed = total_seconds(utcnow() - last_heartbeat)
+    return abs(elapsed) <= FLAGS.service_down_time
+
+
+def generate_mac_address():
+    """Generate an Ethernet MAC address."""
+    mac = [0x02, 0x16, 0x3e,
+           random.randint(0x00, 0x7f),
+           random.randint(0x00, 0xff),
+           random.randint(0x00, 0xff)]
+    return ':'.join(map(lambda x: "%02x" % x, mac))
+
+
+def read_file_as_root(file_path):
+    """Secure helper to read file as root."""
+    try:
+        out, _err = execute('cat', file_path, run_as_root=True)
+        return out
+    except exception.ProcessExecutionError:
+        raise exception.FileNotFound(file_path=file_path)
diff -Naurp nova.orig/nova/virt/libvirt/connection.py nova/nova/virt/libvirt/connection.py
--- nova.orig/nova/virt/libvirt/connection.py	2012-02-27 09:01:19.401005813 -0500
+++ nova/nova/virt/libvirt/connection.py	2012-02-27 09:05:08.413011273 -0500
@@ -39,16 +39,20 @@ Supports KVM, LXC, QEMU, UML, and XEN.
 
 """
 
+import errno
 import hashlib
 import functools
 import glob
 import multiprocessing
 import os
+import select
 import shutil
+import stat
 import sys
 import tempfile
 import uuid
 
+import eventlet
 from eventlet import greenthread
 from xml.dom import minidom
 from xml.etree import ElementTree
@@ -152,6 +156,9 @@ libvirt_opts = [
                help='Override the default disk prefix for the devices attached'
                     ' to a server, which is dependent on libvirt_type. '
                     '(valid options are: sd, xvd, uvd, vd)'),
+    cfg.IntOpt('libvirt_console_log_size',
+               default=65536,
+               help='libvirt console log ringbugger size')
     ]
 
 FLAGS = flags.FLAGS
@@ -185,6 +192,57 @@ def _get_eph_disk(ephemeral):
     return 'disk.eph' + str(ephemeral['num'])
 
 
+class ConsoleLogger(object):
+
+    def __init__(self, fifo_path, ringbuffer_path):
+        self.fifo_path = fifo_path
+        self.fd = None
+        self.data_queue = eventlet.queue.LightQueue(0)
+        self.ringbuffer = utils.RingBuffer(ringbuffer_path,
+                                           FLAGS.libvirt_console_log_size)
+        self.reader_thread = eventlet.spawn(self._reader_thread_func)
+        self.writer_thread = eventlet.spawn(self._writer_thread_func)
+
+    def _reopen(self):
+        if self.fd is not None:
+            os.close(self.fd)
+            self.fd = None
+        self.fd = os.open(self.fifo_path, os.O_RDONLY | os.O_NONBLOCK)
+
+    def _reader_thread_func(self):
+        self._reopen()
+        while True:
+            select.select([self.fd], [], [])
+            data = os.read(self.fd, 1024)
+            if data:
+                self.data_queue.put(data)
+            else:
+                self._reopen()
+
+    def _writer_thread_func(self):
+        try:
+            data = self.data_queue.get()
+            while data:
+                self.ringbuffer.write(data)
+                data = self.data_queue.get()
+        finally:
+            self.ringbuffer.close()
+
+    def close(self):
+        self.reader_thread.kill()
+        self.data_queue.put(None)
+        try:
+            self.writer_thread.wait()
+        except eventlet.greenlet.GreenletExit:
+            pass
+        if self.fd is not None:
+            os.close(self.fd)
+            self.fd = None
+
+    def peek(self):
+        return self.ringbuffer.peek()
+
+
 class LibvirtConnection(driver.ComputeDriver):
 
     def __init__(self, read_only):
@@ -218,6 +276,8 @@ class LibvirtConnection(driver.ComputeDr
 
         self.image_cache_manager = imagecache.ImageCacheManager()
 
+        self.console_loggers = dict()
+
     @property
     def host_state(self):
         if not self._host_state:
@@ -226,7 +286,11 @@ class LibvirtConnection(driver.ComputeDr
 
     def init_host(self, host):
         # NOTE(nsokolov): moved instance restarting to ComputeManager
-        pass
+        for name in self.list_instances():
+            base_path = os.path.join(FLAGS.instances_path, name)
+            fifo_path = os.path.join(base_path, 'console.fifo.out')
+            ringbuffer_path = os.path.join(base_path, 'console.ring')
+            self._start_console_logger(name, fifo_path, ringbuffer_path)
 
     @property
     def libvirt_xml(self):
@@ -303,6 +367,15 @@ class LibvirtConnection(driver.ComputeDr
         return [self._conn.lookupByID(x).name()
                 for x in self._conn.listDomainsID()
                 if x != 0]  # We skip domains with ID 0 (hypervisors).
+                
+    def _start_console_logger(self, name, fifo_path, ringbuffer_path):
+        self._stop_console_logger(name)
+        self.console_loggers[name] = ConsoleLogger(fifo_path, ringbuffer_path)
+
+    def _stop_console_logger(self, name):
+        if name in self.console_loggers:
+            self.console_loggers[name].close()
+            del self.console_loggers[name]
 
     @staticmethod
     def _map_to_instance_info(domain):
@@ -428,6 +501,7 @@ class LibvirtConnection(driver.ComputeDr
     def _cleanup(self, instance):
         target = os.path.join(FLAGS.instances_path, instance['name'])
         instance_name = instance['name']
+        self._stop_console_logger(instance_name)
         LOG.info(_('Deleting instance files %(target)s') % locals(),
                  instance=instance)
         if FLAGS.libvirt_type == 'lxc':
@@ -859,10 +933,10 @@ class LibvirtConnection(driver.ComputeDr
 
     @exception.wrap_exception()
     def get_console_output(self, instance):
-        console_log = os.path.join(FLAGS.instances_path, instance['name'],
-                                   'console.log')
+        console_fifo = os.path.join(FLAGS.instances_path, instance['name'],
+                                   'console.fifo.out')
 
-        libvirt_utils.chown(console_log, os.getuid())
+        libvirt_utils.chown(console_fifo, os.getuid())
 
         if FLAGS.libvirt_type == 'xen':
             # Xen is special
@@ -870,14 +944,12 @@ class LibvirtConnection(driver.ComputeDr
                                          'ttyconsole',
                                          instance['name'])
             data = self._flush_xen_console(virsh_output)
-            fpath = self._append_to_file(data, console_log)
+            self._append_to_file(data, console_fifo)
         elif FLAGS.libvirt_type == 'lxc':
             # LXC is also special
             LOG.info(_("Unable to read LXC console"), instance=instance)
-        else:
-            fpath = console_log
 
-        return libvirt_utils.load_file(fpath)
+        return self.console_loggers[instance['name']].peek()
 
     @staticmethod
     def get_host_ip_addr():
@@ -1003,8 +1075,25 @@ class LibvirtConnection(driver.ComputeDr
             container_dir = '%s/rootfs' % basepath(suffix='')
             libvirt_utils.ensure_tree(container_dir)
 
-        # NOTE(vish): No need add the suffix to console.log
-        libvirt_utils.write_to_file(basepath('console.log', ''), '', 007)
+        # NOTE(vish): No need add the suffix
+        console_fifo = basepath('console.fifo', '')
+        console_ring = basepath('console.ring', '')
+
+        for fifo_suffix in ['.in', '.out']: 
+            console_fifo_suffix = console_fifo + fifo_suffix
+            try:
+                console_fifo_stat = os.stat(console_fifo_suffix)
+            except OSError, e:
+                if e.errno == errno.ENOENT:
+                    os.mkfifo(console_fifo_suffix, 0660)
+                else:
+                    raise
+            else:
+                utils.execute('chown', os.getuid(), console_fifo,
+                              run_as_root=True)
+        self._start_console_logger(instance['name'],
+                                   console_fifo + '.out',
+                                   console_ring)
 
         if not disk_images:
             disk_images = {'image_id': instance['image_ref'],
diff -Naurp nova.orig/nova/virt/libvirt.xml.template nova/nova/virt/libvirt.xml.template
--- nova.orig/nova/virt/libvirt.xml.template	2012-02-27 09:01:19.401005813 -0500
+++ nova/nova/virt/libvirt.xml.template	2012-02-27 09:03:45.373009293 -0500
@@ -160,8 +160,8 @@
 
 #end for
         <!-- The order is significant here.  File must be defined first -->
-        <serial type="file">
-            <source path='${basepath}/console.log'/>
+        <serial type="pipe">
+            <source path='${basepath}/console.fifo'/>
             <target port='1'/>
         </serial>
 
